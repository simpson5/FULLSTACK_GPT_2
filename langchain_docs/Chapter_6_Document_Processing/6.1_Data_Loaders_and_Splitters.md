# ğŸ“– Section 6.1: Data Loaders and Splitters - RAGì˜ ì²« ê±¸ìŒ

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- âœ… ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹(PDF, TXT, DOCX)ì„ LangChainìœ¼ë¡œ ë¡œë”©í•˜ëŠ” ë°©ë²• ìŠµë“
- âœ… UnstructuredFileLoaderì˜ ê°•ë ¥í•œ í†µí•© ë¡œë”© ê¸°ëŠ¥ ì´í•´
- âœ… ë¬¸ì„œ ë¶„í• ì˜ í•„ìš”ì„±ê³¼ ë‹¤ì–‘í•œ ë¶„í•  ì „ëµ í•™ìŠµ
- âœ… chunk_sizeì™€ chunk_overlap ë§¤ê°œë³€ìˆ˜ì˜ ìµœì í™” ë°©ë²• ìµíˆê¸°

## ğŸ§  í•µì‹¬ ê°œë…

### ë¬¸ì„œ ë¡œë”©ì´ë€?
**Document Loading**ì€ ë‹¤ì–‘í•œ í˜•ì‹ì˜ ì™¸ë¶€ ë°ì´í„°ë¥¼ LangChainì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” `Document` ê°ì²´ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

```mermaid
graph LR
    A[ì›ë³¸ íŒŒì¼<br/>PDF/TXT/DOCX] --> B[Document Loader] 
    B --> C[LangChain Document<br/>page_content + metadata]
    
    style A fill:#FFE6E6
    style C fill:#E6FFE6
```

### ë¬¸ì„œ ë¶„í• ì´ í•„ìš”í•œ ì´ìœ 

| ë¬¸ì œ ìƒí™© | í•´ê²°ì±… |
|-----------|--------|
| **í† í° ì œí•œ** | í° ë¬¸ì„œëŠ” LLM ì…ë ¥ ì œí•œì„ ì´ˆê³¼ |
| **ê²€ìƒ‰ ì •í™•ë„** | ì‘ì€ ì²­í¬ê°€ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ |
| **ë¹„ìš© íš¨ìœ¨ì„±** | ê´€ë ¨ ë¶€ë¶„ë§Œ LLMì—ê²Œ ì œê³µí•˜ì—¬ ë¹„ìš© ì ˆì•½ |
| **ì˜ë¯¸ ë³´ì¡´** | ë¬¸ë‹¨ì´ë‚˜ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ë§¥ë½ ìœ ì§€ |

## ğŸ“‹ ì£¼ìš” í´ë˜ìŠ¤/í•¨ìˆ˜ ë ˆí¼ëŸ°ìŠ¤

### UnstructuredFileLoader
```python
from langchain.document_loaders import UnstructuredFileLoader

class UnstructuredFileLoader(BaseLoader):
    def __init__(
        self, 
        file_path: str,              # ğŸ“Œ í•„ìˆ˜: ë¡œë”©í•  íŒŒì¼ ê²½ë¡œ
        mode: str = "single",        # ğŸ“Œ ì„ íƒ: "single" ë˜ëŠ” "paged" ëª¨ë“œ
        **kwargs
    ):
        """
        ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ í†µí•© ì§€ì›í•˜ëŠ” ë²”ìš© ë¬¸ì„œ ë¡œë”
        
        ì§€ì› í˜•ì‹: PDF, TXT, DOCX, HTML, PowerPoint, ì´ë¯¸ì§€ ë“±
        """
```

**ğŸ“Œ ì£¼ìš” íŠ¹ì§•**:
- **í†µí•©ì„±**: í•˜ë‚˜ì˜ ë¡œë”ë¡œ ëª¨ë“  íŒŒì¼ í˜•ì‹ ì²˜ë¦¬
- **ìë™ ê°ì§€**: íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ ì²˜ë¦¬ ë°©ì‹ ì„ íƒ
- **ì˜ì¡´ì„± ê´€ë¦¬**: í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ

### RecursiveCharacterTextSplitter
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

class RecursiveCharacterTextSplitter(TextSplitter):
    def __init__(
        self,
        chunk_size: int = 4000,        # ğŸ“Œ ìš©ë„: ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜
        chunk_overlap: int = 200,      # ğŸ“Œ ìš©ë„: ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜
        separators: List[str] = None   # ğŸ“Œ ìš©ë„: ë¶„í•  ê¸°ì¤€ ë¬¸ìë“¤
    ):
        """
        ë¬¸ì„œë¥¼ ì¬ê·€ì ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ì§€ëŠ¥í˜• í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        """
```

**ğŸ“Œ ë¶„í•  ìš°ì„ ìˆœìœ„**:
1. ë¬¸ë‹¨ êµ¬ë¶„ (`\n\n`)
2. ë¬¸ì¥ êµ¬ë¶„ (`\n`)  
3. ë‹¨ì–´ êµ¬ë¶„ (` `)
4. ë¬¸ì ë‹¨ìœ„ ë¶„í• 

### CharacterTextSplitter
```python
from langchain.text_splitter import CharacterTextSplitter

class CharacterTextSplitter(TextSplitter):
    def __init__(
        self,
        separator: str = "\n\n",       # ğŸ“Œ ìš©ë„: ë¶„í•  ê¸°ì¤€ ë¬¸ì
        chunk_size: int = 1000,        # ğŸ“Œ ìš©ë„: ìµœëŒ€ ì²­í¬ í¬ê¸°
        chunk_overlap: int = 200       # ğŸ“Œ ìš©ë„: ì²­í¬ ê²¹ì¹¨ í¬ê¸°
    ):
        """
        ì§€ì •ëœ êµ¬ë¶„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„í• í•˜ëŠ” ë‹¨ìˆœ ë¶„í• ê¸°
        """
```

## ğŸ”§ ë™ì‘ ê³¼ì • ìƒì„¸

### 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë”© ê¸°ë³¸ ì‚¬ìš©ë²•
```python
# === Step 1: ë‹¤ì–‘í•œ ë¡œë”ë“¤ì˜ ê¸°ë³¸ ì‚¬ìš©ë²• ===

# ğŸ“Œ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”©
from langchain.document_loaders import TextLoader
text_loader = TextLoader("./files/chapter_one.txt")
text_docs = text_loader.load()

# ğŸ“Œ PDF íŒŒì¼ ë¡œë”©  
from langchain.document_loaders import PyPDFLoader
pdf_loader = PyPDFLoader("./files/chapter_one.pdf")
pdf_docs = pdf_loader.load()

# ğŸ“Œ í†µí•© ë¡œë” ì‚¬ìš© (ê¶Œì¥)
from langchain.document_loaders import UnstructuredFileLoader
loader = UnstructuredFileLoader("./files/chapter_one.docx")
docs = loader.load()

print(f"ë¡œë”©ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
print(f"ì²« ë²ˆì§¸ ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {docs[0].page_content[:200]}...")
```

### 2ë‹¨ê³„: ë¬¸ì„œ ë¶„í•  ì „ëµ
```python
# === Step 2: ê¸°ë³¸ ë¶„í•  vs ì§€ëŠ¥í˜• ë¶„í•  ===

from langchain.text_splitter import RecursiveCharacterTextSplitter

# ğŸ§  ê°œë…: ë¬¸ì„œê°€ ë„ˆë¬´ í´ ë•Œì˜ ë¬¸ì œì  í™•ì¸
print(f"ì›ë³¸ ë¬¸ì„œ ê¸¸ì´: {len(docs[0].page_content)} ë¬¸ì")
print(f"ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")  # ì¼ë°˜ì ìœ¼ë¡œ 1ê°œ

# ğŸ“Œ ì§€ëŠ¥í˜• ë¶„í• ê¸° ìƒì„±
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,    # ğŸ“Œ ê° ì²­í¬ëŠ” ìµœëŒ€ 1000ì
    chunk_overlap=100   # ğŸ“Œ ì¸ì ‘ ì²­í¬ ê°„ 100ì ê²¹ì¹¨
)

# ğŸ”§ ë¶„í•  ì‹¤í–‰
split_docs = splitter.split_documents(docs)
print(f"ë¶„í•  í›„ ë¬¸ì„œ ê°œìˆ˜: {len(split_docs)}")
```

### 3ë‹¨ê³„: ë¡œë”©ê³¼ ë¶„í•  í†µí•©
```python
# === Step 3: ë¡œë”©ê³¼ ë¶„í• ì„ í•œ ë²ˆì— ì²˜ë¦¬ ===

# ğŸ’¡ ì‹¤ë¬´ íŒ: load_and_split() ë©”ì„œë“œ í™œìš©
loader = UnstructuredFileLoader("./files/chapter_one.docx")
split_docs = loader.load_and_split(text_splitter=splitter)

print(f"âœ… í•œ ë²ˆì— ë¡œë”© ë° ë¶„í•  ì™„ë£Œ: {len(split_docs)}ê°œ ì²­í¬")

# ğŸ“Š ë¶„í•  ê²°ê³¼ í™•ì¸
for i, doc in enumerate(split_docs[:3]):  # ì²« 3ê°œ ì²­í¬ë§Œ í™•ì¸
    print(f"\n--- ì²­í¬ {i+1} ---")
    print(f"ê¸¸ì´: {len(doc.page_content)} ë¬¸ì")
    print(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100]}...")
```

## ğŸ’» ì‹¤ì „ ì˜ˆì œ

### ì™„ì „í•œ ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
```python
import os
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# === 1ë‹¨ê³„: íŒŒì¼ ì¡´ì¬ í™•ì¸ ===
file_path = "./files/chapter_one.docx"
if not os.path.exists(file_path):
    print("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. íŒŒì¼ì„ files/ í´ë”ì— ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
    exit()

# === 2ë‹¨ê³„: ë¬¸ì„œ ë¡œë” ì„¤ì • ===
# ğŸ§  ê°œë…: UnstructuredFileLoaderëŠ” íŒŒì¼ í˜•ì‹ì„ ìë™ ê°ì§€
loader = UnstructuredFileLoader(file_path)

# === 3ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì • ===  
# ğŸ’¡ ì‹¤ë¬´ íŒ: ë¬¸ì„œ íƒ€ì…ì— ë”°ë¥¸ ìµœì í™” ë§¤ê°œë³€ìˆ˜
splitter = RecursiveCharacterTextSplitter(
    chunk_size=600,     # ğŸ“Œ ì¤‘ê°„ í¬ê¸°: ë„ˆë¬´ í¬ì§€ë„ ì‘ì§€ë„ ì•Šê²Œ
    chunk_overlap=100,  # ğŸ“Œ ì ì ˆí•œ ê²¹ì¹¨: ë¬¸ë§¥ ì—°ê²°ì„± ìœ ì§€
    separators=[        # ğŸ“Œ í•œêµ­ì–´ ë¬¸ì„œì— ìµœì í™”ëœ êµ¬ë¶„ì
        "\n\n",         # ë¬¸ë‹¨ êµ¬ë¶„ (ìµœìš°ì„ )
        "\n",           # ì¤„ êµ¬ë¶„  
        ".",            # ë¬¸ì¥ êµ¬ë¶„
        " "             # ë‹¨ì–´ êµ¬ë¶„ (ìµœí›„)
    ]
)

# === 4ë‹¨ê³„: ë¡œë”© ë° ë¶„í•  ì‹¤í–‰ ===
try:
    documents = loader.load_and_split(text_splitter=splitter)
    
    print("ğŸ‰ ë¬¸ì„œ ì²˜ë¦¬ ì„±ê³µ!")
    print(f"ğŸ“Š í†µê³„:")
    print(f"   - ì´ ì²­í¬ ìˆ˜: {len(documents)}")
    
    # ì²­í¬ í¬ê¸° ë¶„í¬ í™•ì¸
    chunk_sizes = [len(doc.page_content) for doc in documents]
    print(f"   - í‰ê·  ì²­í¬ í¬ê¸°: {sum(chunk_sizes) // len(chunk_sizes)} ë¬¸ì")
    print(f"   - ìµœëŒ€ ì²­í¬ í¬ê¸°: {max(chunk_sizes)} ë¬¸ì")
    print(f"   - ìµœì†Œ ì²­í¬ í¬ê¸°: {min(chunk_sizes)} ë¬¸ì")
    
    # === 5ë‹¨ê³„: ë¶„í•  í’ˆì§ˆ ê²€ì¦ ===
    print("\nğŸ” ë¶„í•  í’ˆì§ˆ ê²€ì¦:")
    
    # ê²¹ì¹¨ í™•ì¸
    if len(documents) > 1:
        overlap_found = False
        for i in range(len(documents) - 1):
            current_end = documents[i].page_content[-50:]  # ë§ˆì§€ë§‰ 50ì
            next_start = documents[i+1].page_content[:50]   # ì²« 50ì
            
            # ê²¹ì¹˜ëŠ” ë¶€ë¶„ì´ ìˆëŠ”ì§€ í™•ì¸
            for j in range(10, 50):  # ìµœì†Œ 10ì ì´ìƒ ê²¹ì³ì•¼ ìœ ì˜ë¯¸
                if current_end[-j:] in next_start:
                    overlap_found = True
                    print(f"   âœ… ì²­í¬ {i+1}ê³¼ {i+2} ì‚¬ì´ì— {j}ì ê²¹ì¹¨ ë°œê²¬")
                    break
        
        if not overlap_found:
            print("   âš ï¸ ì²­í¬ ê°„ ê²¹ì¹¨ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. chunk_overlap ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("ğŸ’¡ í•´ê²° ë°©ë²•:")
    print("   1. íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
    print("   2. íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸") 
    print("   3. unstructured íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install unstructured")
```

## ğŸ” ë³€ìˆ˜/í•¨ìˆ˜ ìƒì„¸ ì„¤ëª…

### í•µì‹¬ ë§¤ê°œë³€ìˆ˜ ìµœì í™”

#### chunk_size ì„¤ì • ê°€ì´ë“œ
```python
# ğŸ“Œ ìš©ë„: ê° ì²­í¬ì˜ ìµœëŒ€ í¬ê¸° ì„¤ì •, íƒ€ì…: int

# ì‘ì€ í¬ê¸° (200-500ì)
chunk_size_small = 300
# ì¥ì : ì •í™•í•œ ê²€ìƒ‰, ë¹ ë¥¸ ì²˜ë¦¬
# ë‹¨ì : ë¬¸ë§¥ ì†ì‹¤ ê°€ëŠ¥, ë§ì€ ì²­í¬ ìƒì„±

# ì¤‘ê°„ í¬ê¸° (500-1000ì) - ê¶Œì¥
chunk_size_medium = 600  
# ì¥ì : ë¬¸ë§¥ê³¼ ì •í™•ì„±ì˜ ê· í˜•
# ë‹¨ì : ìƒí™©ì— ë”°ë¼ ì¡°ì • í•„ìš”

# í° í¬ê¸° (1000-2000ì)
chunk_size_large = 1500
# ì¥ì : í’ë¶€í•œ ë¬¸ë§¥ ì •ë³´
# ë‹¨ì : ê²€ìƒ‰ ì •í™•ë„ ì €í•˜, í† í° ë¹„ìš© ì¦ê°€
```

#### chunk_overlap ìµœì í™”
```python
# ğŸ“Œ ìš©ë„: ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„ í¬ê¸°, íƒ€ì…: int

def calculate_optimal_overlap(chunk_size: int) -> int:
    """
    ğŸ“‹ ê¸°ëŠ¥: ì²­í¬ í¬ê¸°ì— ë”°ë¥¸ ìµœì  ê²¹ì¹¨ í¬ê¸° ê³„ì‚°
    ğŸ’¡ ê²½í—˜ ë²•ì¹™: ì²­í¬ í¬ê¸°ì˜ 10-20%ê°€ ì ì ˆ
    """
    if chunk_size <= 300:
        return chunk_size // 10      # 10% ê²¹ì¹¨
    elif chunk_size <= 1000:
        return chunk_size // 8       # 12.5% ê²¹ì¹¨  
    else:
        return chunk_size // 6       # 16.7% ê²¹ì¹¨

# ì‚¬ìš© ì˜ˆì‹œ
chunk_size = 600
optimal_overlap = calculate_optimal_overlap(chunk_size)
print(f"ğŸ“Š ê¶Œì¥ ê²¹ì¹¨ í¬ê¸°: {optimal_overlap}ì (ì „ì²´ì˜ {optimal_overlap/chunk_size*100:.1f}%)")
```

### ê³ ê¸‰ ë¶„í•  ì „ëµ
```python
# === ë¬¸ì„œ íƒ€ì…ë³„ ë§ì¶¤ ë¶„í•  ì „ëµ ===

def create_splitter_for_document_type(doc_type: str) -> RecursiveCharacterTextSplitter:
    """
    ğŸ“‹ ê¸°ëŠ¥: ë¬¸ì„œ íƒ€ì…ì— ë”°ë¥¸ ìµœì í™”ëœ ë¶„í• ê¸° ìƒì„±
    ğŸ“¥ ì…ë ¥: ë¬¸ì„œ íƒ€ì… ('academic', 'novel', 'technical', 'news')
    ğŸ“¤ ì¶œë ¥: ìµœì í™”ëœ TextSplitter ê°ì²´
    """
    
    if doc_type == "academic":
        # í•™ìˆ  ë…¼ë¬¸: ê¸´ ë¬¸ë‹¨, í° ì²­í¬ í•„ìš”
        return RecursiveCharacterTextSplitter(
            chunk_size=1200,
            chunk_overlap=200,
            separators=["\n\n", "\n", ". ", " "]
        )
    
    elif doc_type == "novel":
        # ì†Œì„¤: ë¬¸ë‹¨ê³¼ ëŒ€í™” êµ¬ë¶„ ì¤‘ìš”
        return RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=100,
            separators=["\n\n", "\n", '"', ". ", " "]
        )
    
    elif doc_type == "technical":
        # ê¸°ìˆ  ë¬¸ì„œ: ì½”ë“œ ë¸”ë¡ê³¼ ì„¤ëª… êµ¬ë¶„
        return RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=150,
            separators=["\n\n", "\n", "```", ". ", " "]
        )
    
    else:  # ì¼ë°˜ ë¬¸ì„œ
        return RecursiveCharacterTextSplitter(
            chunk_size=600,
            chunk_overlap=100
        )

# ì‚¬ìš© ì˜ˆì‹œ
novel_splitter = create_splitter_for_document_type("novel")
technical_splitter = create_splitter_for_document_type("technical")
```

## ğŸ§ª ì‹¤ìŠµ ê³¼ì œ

### ğŸ”¨ ê¸°ë³¸ ê³¼ì œ
1. **ë‹¤ì¤‘ íŒŒì¼ ë¡œë”©**: PDF, TXT, DOCX íŒŒì¼ì„ ê°ê° ë¡œë”©í•˜ì—¬ ê²°ê³¼ ë¹„êµ
```python
# TODO: ì„¸ ê°€ì§€ íŒŒì¼ í˜•ì‹ì„ ë¡œë”©í•˜ê³  ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„° ë¹„êµ
files = ["chapter.txt", "chapter.pdf", "chapter.docx"]
# íŒíŠ¸: ê° ë¡œë”ì˜ ë©”íƒ€ë°ì´í„°ì—ì„œ ì–´ë–¤ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ì§€ í™•ì¸
```

2. **ë¶„í•  ì „ëµ ë¹„êµ**: chunk_sizeë¥¼ 300, 600, 1200ìœ¼ë¡œ ë³€ê²½í•˜ë©° ê²°ê³¼ ë¶„ì„
```python
# TODO: ë‹¤ì–‘í•œ ì²­í¬ í¬ê¸°ë¡œ ë¶„í•  í›„ ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸
chunk_sizes = [300, 600, 1200]
# íŒíŠ¸: ê° í¬ê¸°ë³„ë¡œ ìƒì„±ë˜ëŠ” ì²­í¬ ìˆ˜ì™€ í‰ê·  ë¬¸ì ìˆ˜ ë¹„êµ
```

### ğŸš€ ì‹¬í™” ê³¼ì œ
3. **ê²¹ì¹¨ íš¨ê³¼ ë¶„ì„**: chunk_overlapì„ 0, 50, 100, 200ìœ¼ë¡œ ë³€ê²½í•˜ë©° íš¨ê³¼ ì¸¡ì •
```python
# TODO: ê²¹ì¹¨ ì„¤ì •ì´ ë¬¸ë§¥ ì—°ê²°ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
def analyze_chunk_continuity(documents, overlap_size):
    """ì²­í¬ ê°„ ì—°ê²°ì„± ì ìˆ˜ ê³„ì‚°"""
    pass
```

4. **ë§ì¶¤í˜• ë¶„í• ê¸° ê°œë°œ**: íŠ¹ì • ë¬¸ì„œ í˜•ì‹ì— ìµœì í™”ëœ ë¶„í• ê¸° êµ¬í˜„
```python
# TODO: ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¥¼ ìœ„í•œ ì „ìš© ë¶„í• ê¸° êµ¬í˜„
class MarkdownAwareTextSplitter(RecursiveCharacterTextSplitter):
    """ë§ˆí¬ë‹¤ìš´ êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ì§€ëŠ¥í˜• ë¶„í• ê¸°"""
    
    def __init__(self, **kwargs):
        # ë§ˆí¬ë‹¤ìš´ êµ¬ë¶„ì ì¶”ê°€: ##, ###, -, *, ë“±
        separators = ["\n## ", "\n### ", "\n- ", "\n* ", "\n\n", "\n", " "]
        super().__init__(separators=separators, **kwargs)
```

### ğŸ’¡ ì°½ì˜ ê³¼ì œ
5. **ë™ì  ì²­í¬ í¬ê¸° ì¡°ì ˆ**: ë¬¸ì„œ ë‚´ìš©ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì²­í¬ í¬ê¸° ì¡°ì ˆ
```python
# TODO: ë¬¸ì„œì˜ ë³µì¡ë„ì— ë”°ë¼ ì²­í¬ í¬ê¸°ë¥¼ ë™ì  ì¡°ì ˆí•˜ëŠ” ì‹œìŠ¤í…œ
def adaptive_chunk_size(text_complexity_score):
    """í…ìŠ¤íŠ¸ ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘í˜• ì²­í¬ í¬ê¸° ê³„ì‚°"""
    pass
```

6. **í’ˆì§ˆ ì§€í‘œ ê°œë°œ**: ë¶„í•  í’ˆì§ˆì„ ìë™ í‰ê°€í•˜ëŠ” ì§€í‘œ ì‹œìŠ¤í…œ
```python
# TODO: ë¶„í•  í’ˆì§ˆì„ ìˆ˜ì¹˜í™”í•˜ëŠ” í‰ê°€ ì‹œìŠ¤í…œ
def evaluate_split_quality(original_doc, split_docs):
    """
    ë¶„í•  í’ˆì§ˆ ì§€í‘œ:
    - ì˜ë¯¸ì  ì¼ê´€ì„± ì ìˆ˜
    - ì •ë³´ ì†ì‹¤ë¥   
    - ê²€ìƒ‰ íš¨ìœ¨ì„± ì ìˆ˜
    """
    pass
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­
```python
# âŒ ë¹„íš¨ìœ¨ì ì¸ ë°©ë²•
for file_path in large_file_list:
    loader = UnstructuredFileLoader(file_path)
    docs = loader.load()  # ë§¤ë²ˆ ìƒˆë¡œìš´ ë¡œë” ìƒì„±

# âœ… íš¨ìœ¨ì ì¸ ë°©ë²•  
def batch_load_documents(file_paths: List[str]) -> List[Document]:
    """ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë¡œë”©"""
    all_docs = []
    for file_path in file_paths:
        try:
            loader = UnstructuredFileLoader(file_path)
            docs = loader.load()
            all_docs.extend(docs)
        except Exception as e:
            print(f"âš ï¸ {file_path} ë¡œë”© ì‹¤íŒ¨: {e}")
    return all_docs
```

### ë©”ëª¨ë¦¬ ê´€ë¦¬
- **í° íŒŒì¼ ì²˜ë¦¬**: ë©”ëª¨ë¦¬ ë¶€ì¡±ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ streaming ì²˜ë¦¬ ê³ ë ¤
- **ë¶„í•  ê²°ê³¼ ìºì‹±**: ë™ì¼í•œ ë¬¸ì„œì˜ ë°˜ë³µ ì²˜ë¦¬ ì‹œ ê²°ê³¼ ìºì‹±
- **ê°€ë¹„ì§€ ì»¬ë ‰ì…˜**: ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ í›„ ëª…ì‹œì  ë©”ëª¨ë¦¬ í•´ì œ

### ë¬¸ì„œ í˜•ì‹ë³„ ì£¼ì˜ì 
- **PDF**: ìŠ¤ìº”ëœ PDFëŠ” OCR í•„ìš”, ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ì£¼ì˜
- **DOCX**: í‘œì™€ ì´ë¯¸ì§€ ì²˜ë¦¬ ë°©ì‹ í™•ì¸
- **HTML**: íƒœê·¸ ì œê±° ì •ë„ ì¡°ì ˆ í•„ìš”

## ğŸ”— ê´€ë ¨ ìë£Œ
- **ì´ì „ í•™ìŠµ**: [6.0 Introduction](./6.0_Introduction.md)
- **ë‹¤ìŒ í•™ìŠµ**: [6.2 Tiktoken](./6.2_Tiktoken.md)
- **ì°¸ê³  ë¬¸ì„œ**: [LangChain Document Loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders/)
- **ì‹¤ìŠµ íŒŒì¼**: [6.1 Data Loaders and Splitters.ipynb](../../00%20lecture/6.1%20Data%20Loaders%20and%20Splitters.ipynb)

---

ğŸ’¡ **í•µì‹¬ ì •ë¦¬**: ë¬¸ì„œ ë¡œë”©ê³¼ ë¶„í• ì€ RAG ì‹œìŠ¤í…œì˜ ì²« ë‹¨ê³„ë¡œ, í’ˆì§ˆ ì¢‹ì€ ì²­í¬ ìƒì„±ì´ ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ì¢Œìš°í•©ë‹ˆë‹¤. `UnstructuredFileLoader`ë¡œ ë‹¤ì–‘í•œ í˜•ì‹ì„ í†µí•© ì²˜ë¦¬í•˜ê³ , `RecursiveCharacterTextSplitter`ë¡œ ì§€ëŠ¥ì  ë¶„í• ì„ í†µí•´ ì˜ë¯¸ ìˆëŠ” ì²­í¬ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.