# ğŸ“– Section 6.5: LangSmith - ì²´ì¸ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹… í”Œë«í¼

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- âœ… RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì²´ì¸ ê´€ì°°ì„±ê³¼ ë””ë²„ê¹…ì˜ ì¤‘ìš”ì„± ì´í•´
- âœ… ì¢…í•©ì ì¸ ì²´ì¸ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ LangSmith ì„¤ì • ë°©ë²• í•™ìŠµ
- âœ… ë³µì¡í•œ ì²´ì¸ ë””ë²„ê¹…ì„ ìœ„í•œ LangSmith ì‹œê°í™” ë„êµ¬ ë§ˆìŠ¤í„°
- âœ… ì²´ì¸ ì‹¤í–‰ í”Œë¡œìš°ì™€ ì„±ëŠ¥ ì§€í‘œ ë¶„ì„ ì‹¤ìŠµ

## ğŸ§  í•µì‹¬ ê°œë…

### LangSmithë€?
**LangSmith**ëŠ” LangChainì˜ ê³µì‹ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹… í”Œë«í¼ìœ¼ë¡œ, LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ ì¢…í•©ì ì¸ ê´€ì°°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ì²´ì¸ ì‹¤í–‰ì˜ ì‹¤ì‹œê°„ ì‹œê°í™”, ìƒì„¸í•œ ë¡œê¹…, ì„±ëŠ¥ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

**ì£¼ìš” ì¥ì :**
- **ì™„ì „í•œ ê°€ì‹œì„±**: ì²´ì¸ ì‹¤í–‰ì˜ ëª¨ë“  ë‹¨ê³„ í™•ì¸
- **ë³µì¡í•œ í”Œë¡œìš° ë””ë²„ê¹…**: ê° êµ¬ì„± ìš”ì†Œë¥¼ í†µí•œ ì…ì¶œë ¥ ì¶”ì 
- **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‹¤í–‰ ì‹œê°„ê³¼ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì 
- **ì˜¤ë¥˜ ë¶„ì„**: ì²´ì¸ ì‹¤íŒ¨ë¥¼ ë¹ ë¥´ê²Œ ì‹ë³„í•˜ê³  ì§„ë‹¨
- **í”„ë¡œë•ì…˜ ì¤€ë¹„**: ë¼ì´ë¸Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§ ë° ë¬¸ì œ ê°ì§€

### RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ LangSmithê°€ í•„ìˆ˜ì¸ ì´ìœ 

**RAG ì²´ì¸ ë³µì¡ì„±**: í˜„ëŒ€ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì—¬ëŸ¬ êµ¬ì„± ìš”ì†Œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
- Vector Storeì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
- Prompt template í¬ë§·íŒ…
- LLM ì²˜ë¦¬
- ì‘ë‹µ ìƒì„±
- ì˜¤ë¥˜ ì²˜ë¦¬ ë° fallback

**ê´€ì°°ì„± ì—†ëŠ” ë””ë²„ê¹…ì˜ ì–´ë ¤ì›€**:
```python
# LangSmith ì—†ì´ - ë””ë²„ê¹…ì´ ì–´ë ¤ì›€
chain = retriever | prompt | llm
result = chain.invoke("í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?")
# âŒ ê²°ê³¼ê°€ í‹€ë ¸ë‹¤ë©´, ì–´ë””ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆì„ê¹Œ?
# âŒ ê²€ìƒ‰ì´ ì‹¤íŒ¨í–ˆë‚˜? í”„ë¡¬í”„íŠ¸ê°€ ì˜ëª» êµ¬ì„±ë˜ì—ˆë‚˜?
# âŒ LLMì´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì˜¤í•´í–ˆë‚˜?
```

**LangSmithì™€ í•¨ê»˜ - ì™„ì „í•œ ê°€ì‹œì„±**:
```python
# LangSmithì™€ í•¨ê»˜ - ëª¨ë“  ë‹¨ê³„ê°€ ì¶”ì  ê°€ëŠ¥
chain = retriever | prompt | llm
result = chain.invoke("í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?")
# âœ… ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
# âœ… LLM ì²˜ë¦¬ ì „ í¬ë§·ëœ í”„ë¡¬í”„íŠ¸ í™•ì¸
# âœ… í† í° ì‚¬ìš©ëŸ‰ê³¼ ì‘ë‹µ ì‹œê°„ ì¶”ì 
# âœ… ì •í™•í•œ ì‹¤íŒ¨ ì§€ì  ì‹ë³„
```

## ğŸ”§ ì„¤ì • ê°€ì´ë“œ

### 1ë‹¨ê³„: LangSmith ê°€ì…
1. **LangSmith ë°©ë¬¸**: [langchain.com/langsmith](https://langchain.com/langsmith)ë¡œ ì´ë™
2. **íšŒì›ê°€ì…**: ì´ë©”ì¼ë¡œ ê³„ì • ìƒì„±
3. **ëŒ€ê¸° ëª©ë¡**: ë² íƒ€ ëŒ€ê¸° ëª©ë¡ ë“±ë¡ (ë² íƒ€ ì¤‘ì¸ ê²½ìš°)
4. **ì´ˆëŒ€**: ì´ë©”ì¼ë¡œ ì´ˆëŒ€ ì½”ë“œ ëŒ€ê¸°
5. **ê³„ì • í™œì„±í™”**: ê³„ì • ì„¤ì • ì™„ë£Œ

**í˜„ì¬ ìƒíƒœ í™•ì¸**:
```python
def check_langsmith_status():
    """LangSmith ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    import requests
    
    try:
        response = requests.get("https://smith.langchain.com/", timeout=5)
        if response.status_code == 200:
            print("âœ… LangSmith ì ‘ê·¼ ê°€ëŠ¥")
            return True
        else:
            print("âš ï¸ LangSmith ì´ˆëŒ€ í•„ìš”í•  ìˆ˜ ìˆìŒ")
            return False
    except:
        print("âŒ LangSmithì— ì—°ê²°í•  ìˆ˜ ì—†ìŒ")
        return False

# í˜„ì¬ ìƒíƒœ í™•ì¸
check_langsmith_status()
```

### 2ë‹¨ê³„: API í‚¤ ìƒì„±
1. **LangSmith ë¡œê·¸ì¸**: LangSmith ëŒ€ì‹œë³´ë“œ ì ‘ê·¼
2. **ì„¤ì •ìœ¼ë¡œ ì´ë™**: API í‚¤ ê´€ë¦¬ ì„¹ì…˜ ì°¾ê¸°
3. **ìƒˆ í‚¤ ìƒì„±**: ìƒˆë¡œìš´ API í‚¤ ìƒì„±
4. **í‚¤ ë³µì‚¬**: ìƒì„±ëœ í‚¤ ì•ˆì „í•˜ê²Œ ë³µì‚¬
5. **ì•ˆì „í•œ ì €ì¥**: í™˜ê²½ ì„¤ì •ì„ ìœ„í•´ í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ë³´ê´€

### 3ë‹¨ê³„: í™˜ê²½ ì„¤ì •
**í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜**:
```bash
# .env íŒŒì¼ì— ì¶”ê°€
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_api_key_here
LANGCHAIN_PROJECT=your_project_name  # ì„ íƒì‚¬í•­: ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ ì´ë¦„
```

**ì™„ì „í•œ .env íŒŒì¼ ì˜ˆì‹œ**:
```bash
# OpenAI ì„¤ì •
OPENAI_API_KEY=sk-your-openai-key-here

# LangSmith ì„¤ì •
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=ls_your-langsmith-key-here
LANGCHAIN_PROJECT=RAG_ë¬¸ì„œ_ì²˜ë¦¬

# ê¸°íƒ€ ì„¤ì •
VECTOR_STORE_PATH=./chroma_db
MODEL_NAME=gpt-3.5-turbo
```

### 4ë‹¨ê³„: ì„¤ì • í™•ì¸
```python
import os
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

def verify_langsmith_setup():
    """LangSmith ì„¤ì •ì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸"""
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    required_vars = [
        'LANGCHAIN_TRACING_V2',
        'LANGCHAIN_ENDPOINT', 
        'LANGCHAIN_API_KEY'
    ]
    
    print("ğŸ”§ LangSmith ì„¤ì • í™•ì¸:")
    print("=" * 50)
    
    missing_vars = []
    for var in required_vars:
        value = os.getenv(var)
        if value:
            # ë³´ì•ˆì„ ìœ„í•´ ì‹¤ì œ API í‚¤ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
            display_value = value if var != 'LANGCHAIN_API_KEY' else 'ls_****'
            print(f"âœ… {var}: {display_value}")
        else:
            missing_vars.append(var)
            print(f"âŒ {var}: ëˆ„ë½ë¨")
    
    if missing_vars:
        print(f"\nâš ï¸ ëˆ„ë½ëœ ë³€ìˆ˜: {missing_vars}")
        print(".env íŒŒì¼ì— ì¶”ê°€í•˜ê³  í™˜ê²½ì„ ì¬ì‹œì‘í•˜ì„¸ìš”")
        return False
    
    # ê°„ë‹¨í•œ ì²´ì¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ§ª LangSmith í†µí•© í…ŒìŠ¤íŠ¸:")
    try:
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        prompt = ChatPromptTemplate.from_messages([
            ("human", "ì•ˆë…•í•˜ì„¸ìš”, ì´ê²ƒì€ LangSmith í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. 'LangSmithê°€ ì‘ë™í•©ë‹ˆë‹¤!'ë¼ê³  ì‘ë‹µí•´ì£¼ì„¸ìš”")
        ])
        
        chain = prompt | llm
        response = chain.invoke({})
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ: {response.content}")
        print(f"âœ… LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì¶”ì  ì„¸ë¶€ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# í™•ì¸ ì‹¤í–‰
verify_langsmith_setup()
```

## ğŸ“Š LangSmith ëŒ€ì‹œë³´ë“œ ê°œìš”

### ë©”ì¸ ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥

**1. í”„ë¡œì íŠ¸ ê°œìš”**
```python
def create_langsmith_project():
    """LangSmith í”„ë¡œì íŠ¸ ìƒì„± ë° ì„¤ì •"""
    
    # í”„ë¡œì íŠ¸ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜/ì‹¤í—˜ì„ êµ¬ì„±í•˜ëŠ” ë° ë„ì›€
    project_config = {
        "name": "RAG_ë¬¸ì„œ_ì²˜ë¦¬",
        "description": "6ì¥ - ë¬¸ì„œ ì²˜ë¦¬ ë° ê²€ìƒ‰ ì²´ì¸",
        "tags": ["RAG", "ë¬¸ì„œì²˜ë¦¬", "êµìœ¡"],
        "metadata": {
            "course": "FULLSTACK_GPT",
            "chapter": 6,
            "focus": "Retrieval Augmented Generation"
        }
    }
    
    # í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•´ í”„ë¡œì íŠ¸ ì„¤ì •
    os.environ['LANGCHAIN_PROJECT'] = project_config['name']
    
    return project_config

# í”„ë¡œì íŠ¸ ì„¤ì •
project_info = create_langsmith_project()
print(f"ğŸ“Š LangSmith í”„ë¡œì íŠ¸: {project_info['name']}")
```

**2. ì¶”ì  ì‹œê°í™”**
- **ê³„ì¸µì  ë·°**: ì²´ì¸ êµ¬ì„± ìš”ì†Œ ê°„ ë¶€ëª¨-ìì‹ ê´€ê³„ í™•ì¸
- **íƒ€ì„ë¼ì¸ ë·°**: ì‹¤í–‰ ìˆœì„œì™€ íƒ€ì´ë° ì´í•´
- **ì…ì¶œë ¥ ê²€ì‚¬**: ê° ë‹¨ê³„ì—ì„œì˜ ë°ì´í„° íë¦„ ê²€í† 
- **ì˜¤ë¥˜ ê°•ì¡°**: ì‹¤íŒ¨ ì§€ì ì„ ë¹ ë¥´ê²Œ ì‹ë³„

**3. ì„±ëŠ¥ ì§€í‘œ**
- **ì‹¤í–‰ ì‹œê°„**: ì „ì²´ ë° êµ¬ì„± ìš”ì†Œë³„ íƒ€ì´ë°
- **í† í° ì‚¬ìš©ëŸ‰**: ì…ë ¥ ë° ì¶œë ¥ í† í° ì†Œë¹„
- **ë¹„ìš© ì¶”ì **: ì‹¤í–‰ë³„ API ë¹„ìš© ëª¨ë‹ˆí„°ë§
- **ì„±ê³µë¥ **: ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨ ì¶”ì 

### LangSmith ì¶”ì  í•´ì„

**ì˜ˆì‹œ: Stuff Chain ì¶”ì  ë¶„ì„**
```python
def analyze_stuff_chain_trace():
    """LangSmith ì¶”ì ì—ì„œ ì°¾ì•„ë´ì•¼ í•  ê²ƒë“¤ì˜ ì˜ˆì‹œ"""
    
    trace_analysis = {
        "RunnableParallel": {
            "description": "retrieverì™€ passthroughì˜ ë³‘ë ¬ ì‹¤í–‰",
            "what_to_check": [
                "ë‘ êµ¬ì„± ìš”ì†Œê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ê³  ìˆëŠ”ê°€?",
                "retrieverê°€ ê´€ë ¨ ë¬¸ì„œë¥¼ ë°˜í™˜í•˜ê³  ìˆëŠ”ê°€?",
                "passthroughê°€ ì›ë³¸ ì§ˆë¬¸ì„ ë³´ì¡´í•˜ê³  ìˆëŠ”ê°€?"
            ],
            "common_issues": [
                "ë³‘ë ¬ ì‹¤í–‰ ëŒ€ì‹  ìˆœì°¨ ì‹¤í–‰",
                "ë¹ˆ ë¬¸ì„œ ê²€ìƒ‰",
                "ì§ˆë¬¸ ìˆ˜ì • ë˜ëŠ” ì†ì‹¤"
            ]
        },
        
        "Retriever": {
            "description": "Vector Storeì—ì„œ ë¬¸ì„œ ê²€ìƒ‰",
            "what_to_check": [
                "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜",
                "ê´€ë ¨ì„± ì ìˆ˜ (ê°€ëŠ¥í•œ ê²½ìš°)",
                "ë¬¸ì„œ ë‚´ìš© í’ˆì§ˆ",
                "ê²€ìƒ‰ ì‹¤í–‰ ì‹œê°„"
            ],
            "common_issues": [
                "ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨",
                "ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œ ê²€ìƒ‰", 
                "ëŠë¦° ê²€ìƒ‰ ì„±ëŠ¥",
                "Vector Store ì—°ê²° ì˜¤ë¥˜"
            ]
        },
        
        "ChatPromptTemplate": {
            "description": "ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…",
            "what_to_check": [
                "ì ì ˆí•œ ì»¨í…ìŠ¤íŠ¸ ì£¼ì…",
                "ì§ˆë¬¸ ë°°ì¹˜",
                "í…œí”Œë¦¿ ë³€ìˆ˜ ì¹˜í™˜",
                "ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì¡°"
            ],
            "common_issues": [
                "ì»¨í…ìŠ¤íŠ¸ ë˜ëŠ” ì§ˆë¬¸ ëˆ„ë½",
                "í…œí”Œë¦¿ ë³€ìˆ˜ ì˜¤ë¥˜",
                "ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•´ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹€",
                "ì˜ëª»ëœ ë©”ì‹œì§€ êµ¬ì¡°"
            ]
        },
        
        "ChatOpenAI": {
            "description": "LLM ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±",
            "what_to_check": [
                "ì…ë ¥ í† í° ìˆ˜",
                "ì¶œë ¥ í† í° ìˆ˜",
                "ì‘ë‹µ í’ˆì§ˆ",
                "ì²˜ë¦¬ ì‹œê°„"
            ],
            "common_issues": [
                "ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼",
                "ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹",
                "ë†’ì€ ì§€ì—° ì‹œê°„",
                "API ì†ë„ ì œí•œ"
            ]
        }
    }
    
    return trace_analysis

# ë¶„ì„ ê°€ì´ë“œë¼ì¸ ê°€ì ¸ì˜¤ê¸°
guidelines = analyze_stuff_chain_trace()
for component, info in guidelines.items():
    print(f"\nğŸ” {component}:")
    print(f"   ğŸ“ {info['description']}")
    print(f"   âœ… í™•ì¸ì‚¬í•­: {info['what_to_check'][0]}")
    print(f"   âš ï¸  ë¬¸ì œì : {info['common_issues'][0]}")
```

## ğŸ’» ì‹¤ì „ ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ë³¸ ì²´ì¸ ëª¨ë‹ˆí„°ë§
```python
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.runnables import RunnablePassthrough
import time

def create_monitored_basic_chain():
    """LangSmith ëª¨ë‹ˆí„°ë§ì´ ìˆëŠ” ê¸°ë³¸ ì²´ì¸ ìƒì„±"""
    
    print("ğŸ”— ëª¨ë‹ˆí„°ë§ëœ ê¸°ë³¸ ì²´ì¸ ìƒì„±:")
    print("=" * 50)
    
    # êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.1,
        model_kwargs={"seed": 42}  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´
    )
    
    # ê¸°ì¡´ Vector Store ë¡œë“œ
    embeddings = OpenAIEmbeddings()
    vector_store = Chroma(
        persist_directory="./chroma_db",
        embedding_function=embeddings
    )
    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
        
        ì»¨í…ìŠ¤íŠ¸:
        {context}"""),
        ("human", "{question}")
    ])
    
    # ëª¨ë‹ˆí„°ë§ëœ ì²´ì¸ ìƒì„±
    chain = (
        {
            "context": retriever,
            "question": RunnablePassthrough()
        }
        | prompt 
        | llm
    )
    
    return chain

def test_monitored_chain():
    """ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ìœ¼ë¡œ ì²´ì¸ í…ŒìŠ¤íŠ¸"""
    
    chain = create_monitored_basic_chain()
    
    test_cases = [
        {
            "question": "Winston SmithëŠ” ì–´ë””ì— ì‚´ê³  ìˆë‚˜ìš”?",
            "category": "factual_simple",
            "expected_trace_pattern": "retriever â†’ prompt â†’ llm"
        },
        {
            "question": "1984ë…„ ì†Œì„¤ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì£¼ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?", 
            "category": "analytical_complex",
            "expected_trace_pattern": "retriever â†’ prompt â†’ llm"
        },
        {
            "question": "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë“±ì¥ì¸ë¬¼ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            "category": "no_context_available",
            "expected_trace_pattern": "retriever â†’ prompt â†’ llm (ë¹ˆ ì»¨í…ìŠ¤íŠ¸)"
        }
    ]
    
    print(f"\nğŸ§ª LangSmith ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ì²´ì¸ í…ŒìŠ¤íŠ¸:")
    print("=" * 60)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i}: {test_case['category']}")
        print(f"â“ ì§ˆë¬¸: {test_case['question']}")
        print(f"ğŸ” ì˜ˆìƒ íŒ¨í„´: {test_case['expected_trace_pattern']}")
        
        try:
            start_time = time.time()
            
            # ìë™ìœ¼ë¡œ LangSmithì—ì„œ ì¶”ì  ìƒì„±
            response = chain.invoke(test_case['question'])
            
            execution_time = time.time() - start_time
            
            print(f"âœ… ì‘ë‹µ: {response.content[:100]}...")
            print(f"â±ï¸ ì‹œê°„: {execution_time:.2f}ì´ˆ")
            print(f"ğŸ“Š ìì„¸í•œ ì¶”ì ì€ LangSmithì—ì„œ í™•ì¸")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
    
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. LangSmith ëŒ€ì‹œë³´ë“œ ì—´ê¸°")
    print(f"   2. í”„ë¡œì íŠ¸ë¡œ ì´ë™: {os.getenv('LANGCHAIN_PROJECT', 'default')}")
    print(f"   3. ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì˜ ì¶”ì  ê²€í† ")
    print(f"   4. ì…ì¶œë ¥ íë¦„ê³¼ ì„±ëŠ¥ ë¶„ì„")

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
test_monitored_chain()
```

### ì˜ˆì œ 2: ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê³ ê¸‰ ì²´ì¸
```python
from langchain.callbacks import LangChainTracer
from typing import Any, Dict
import uuid

def create_advanced_monitored_chain():
    """ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„°ì™€ íƒœê·¸ê°€ ìˆëŠ” ì²´ì¸ ìƒì„±"""
    
    def enhanced_retrieval_with_metadata(query: str) -> str:
        """ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²€ìƒ‰ í•¨ìˆ˜"""
        
        # ì¶”ì ì— ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        metadata = {
            "query_length": len(query),
            "query_complexity": "high" if len(query.split()) > 10 else "low",
            "timestamp": time.time(),
            "retrieval_strategy": "similarity_search"
        }
        
        # ê²€ìƒ‰ ìˆ˜í–‰
        docs = retriever.get_relevant_documents(query)
        
        # ë©”íƒ€ë°ì´í„°ë¡œ ë¬¸ì„œ í¬ë§·
        formatted_docs = []
        for i, doc in enumerate(docs, 1):
            doc_metadata = {
                "doc_index": i,
                "content_length": len(doc.page_content),
                "source": doc.metadata.get('source', 'unknown')
            }
            
            content = doc.page_content.strip()
            if len(content) > 400:
                content = content[:400] + "..."
            
            formatted_docs.append(f"[ë¬¸ì„œ {i}]\n{content}")
        
        result = "\n\n".join(formatted_docs) if formatted_docs else "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return result
    
    # ì»¤ìŠ¤í…€ êµ¬ì„± ìš”ì†Œê°€ ìˆëŠ” ì²´ì¸ ìƒì„±
    enhanced_chain = (
        {
            "context": RunnableLambda(enhanced_retrieval_with_metadata),
            "question": RunnablePassthrough()
        }
        | prompt
        | llm
    )
    
    return enhanced_chain

def run_chain_with_custom_metadata():
    """ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„°ì™€ ì„¸ì…˜ ì¶”ì ìœ¼ë¡œ ì²´ì¸ ì‹¤í–‰"""
    
    chain = create_advanced_monitored_chain()
    
    # ê´€ë ¨ ì¿¼ë¦¬ë¥¼ ê·¸ë£¹í™”í•˜ê¸° ìœ„í•œ ì»¤ìŠ¤í…€ ì„¸ì…˜ ID
    session_id = f"session_{uuid.uuid4().hex[:8]}"
    
    queries_with_context = [
        {
            "query": "Winston Smithì˜ ì¼ìƒ ìƒí™œì€ ì–´ë–¤ê°€ìš”?",
            "context": "character_analysis",
            "priority": "high"
        },
        {
            "query": "Victory Mansionsì˜ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "context": "setting_description", 
            "priority": "medium"
        },
        {
            "query": "ì†Œì„¤ 1984ì˜ ì£¼ìš” ê°ˆë“±ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "context": "thematic_analysis",
            "priority": "high"
        }
    ]
    
    print(f"\nğŸ¯ ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„°ë¡œ ê³ ê¸‰ ì²´ì¸ ì‹¤í–‰:")
    print(f"ğŸ“ ì„¸ì…˜ ID: {session_id}")
    print("=" * 60)
    
    for i, query_info in enumerate(queries_with_context, 1):
        print(f"\nğŸ“‹ ì¿¼ë¦¬ {i}: {query_info['context']}")
        print(f"â“ ì§ˆë¬¸: {query_info['query']}")
        print(f"ğŸ”¢ ìš°ì„ ìˆœìœ„: {query_info['priority']}")
        
        # ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ì»¤ìŠ¤í…€ ì„¤ì •
        config = {
            "metadata": {
                "session_id": session_id,
                "query_number": i,
                "query_context": query_info['context'],
                "priority": query_info['priority'],
                "user_type": "student",
                "course_chapter": 6
            },
            "tags": [
                f"chapter_6",
                f"{query_info['context']}", 
                f"priority_{query_info['priority']}"
            ]
        }
        
        try:
            start_time = time.time()
            
            response = chain.invoke(
                query_info['query'],
                config=config
            )
            
            execution_time = time.time() - start_time
            
            print(f"âœ… ì‘ë‹µ: {response.content[:80]}...")
            print(f"â±ï¸ ì‹œê°„: {execution_time:.2f}ì´ˆ")
            print(f"ğŸ·ï¸ íƒœê·¸: {config['tags']}")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
    
    print(f"\nğŸ“Š LangSmith ë¶„ì„ íŒ:")
    print(f"   â€¢ session_idë¡œ í•„í„°ë§: {session_id}")
    print(f"   â€¢ íŒ¨í„´ ë¶„ì„ì„ ìœ„í•´ query_contextë¡œ ê·¸ë£¹í™”")
    print(f"   â€¢ ë†’ì€ ìš°ì„ ìˆœìœ„ vs ì¤‘ê°„ ìš°ì„ ìˆœìœ„ ì¿¼ë¦¬ ì„±ëŠ¥ ë¹„êµ")
    print(f"   â€¢ ìœ ì‚¬í•œ ì»¨í…ìŠ¤íŠ¸ ì „ë°˜ì˜ ì¼ê´€ëœ íŒ¨í„´ í™•ì¸")

# ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
run_chain_with_custom_metadata()
```

## ğŸ“‹ LangSmith ëª¨ë²” ì‚¬ë¡€

### 1. íš¨ê³¼ì ì¸ í”„ë¡œì íŠ¸ êµ¬ì„±
```python
def setup_langsmith_best_practices():
    """ëª¨ë²” ì‚¬ë¡€ì— ë”°ë¥¸ LangSmith ì„¤ì •"""
    
    best_practices = {
        "project_naming": {
            "pattern": "service_environment_version",
            "examples": [
                "rag_production_v1",
                "document_processing_staging_v2",
                "chatbot_development_v1"
            ]
        },
        
        "metadata_standards": {
            "required_fields": [
                "session_id",
                "user_id", 
                "request_type",
                "timestamp"
            ],
            "recommended_fields": [
                "model_version",
                "environment",
                "feature_flags",
                "user_segment"
            ]
        },
        
        "tagging_strategy": {
            "hierarchical": [
                "environment:production",
                "service:rag",
                "component:retrieval",
                "version:1.0"
            ],
            "functional": [
                "user_facing",
                "batch_processing",
                "real_time",
                "experimental"
            ]
        }
    }
    
    return best_practices

# ëª¨ë²” ì‚¬ë¡€ ê°€ì´ë“œ ê°€ì ¸ì˜¤ê¸°
practices = setup_langsmith_best_practices()
print("ğŸ“‹ LangSmith ëª¨ë²” ì‚¬ë¡€:")
for category, details in practices.items():
    print(f"\nğŸ”§ {category.replace('_', ' ').title()}:")
    if isinstance(details, dict):
        for key, value in details.items():
            print(f"   {key}: {value}")
    else:
        for item in details:
            print(f"   â€¢ {item}")
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

âš ï¸ **API í‚¤ ë³´ì•ˆ**: LangSmith API í‚¤ë¥¼ ë²„ì „ ê´€ë¦¬ì— ì»¤ë°‹í•˜ì§€ ë§ˆì„¸ìš”. í™˜ê²½ ë³€ìˆ˜ì™€ ë³´ì•ˆ ì„¤ì • ê´€ë¦¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

âš ï¸ **ë°ì´í„° í”„ë¼ì´ë²„ì‹œ**: ì¶”ì ì—ëŠ” í”„ë¡¬í”„íŠ¸ì™€ ì‘ë‹µì´ í¬í•¨ë©ë‹ˆë‹¤. ë¯¼ê°í•œ ë°ì´í„°ê°€ ì ì ˆíˆ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

âš ï¸ **ë¹„ìš© ê´€ë¦¬**: LangSmith ì¶”ì ì´ ë¹„ìš©ì„ ëˆ„ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì ì ˆí•œ ë³´ì¡´ ì •ì±…ì„ ì„¤ì •í•˜ì„¸ìš”.

âš ï¸ **ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„±**: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶”ì  ì „ì†¡ì„ ìœ„í•´ ì•ˆì •ì ì¸ ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤. ì˜¤í”„ë¼ì¸ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ fallback ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•˜ì„¸ìš”.

## ğŸ§ª ì‹¤ìŠµ ê³¼ì œ

### ğŸ”¨ ê¸°ë³¸ ê³¼ì œ
1. **ê¸°ë³¸ LangSmith ì„¤ì •**
   - LangSmith ê³„ì • ê°€ì…
   - í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
   - ê°„ë‹¨í•œ ì²´ì¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
   - ëŒ€ì‹œë³´ë“œì—ì„œ ì²« ë²ˆì§¸ ì¶”ì  ë¶„ì„

2. **ì¶”ì  ë¶„ì„ ì—°ìŠµ**
   - ì—¬ëŸ¬ ì²´ì¸ ë³€í˜• ìƒì„± (ë‹¤ë¥¸ retriever, í”„ë¡¬í”„íŠ¸)
   - ë‹¤ë¥¸ ì²´ì¸ì—ì„œ ë™ì¼í•œ ì¿¼ë¦¬ ì‹¤í–‰
   - ì¶”ì ì„ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ ì°¨ì´ ì‹ë³„
   - ë°œê²¬ ì‚¬í•­ê³¼ ìµœì í™” ê¶Œì¥ì‚¬í•­ ë¬¸ì„œí™”

### ğŸš€ ì‹¬í™” ê³¼ì œ
3. **ì˜¤ë¥˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸**
   - íŠ¹ì • ì¡°ê±´ì—ì„œ ì˜ë„ì ìœ¼ë¡œ ì‹¤íŒ¨í•˜ëŠ” ì²´ì¸ ì„¤ê³„
   - ì¢…í•©ì ì¸ ì˜¤ë¥˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±
   - LangSmithì—ì„œ ì˜¤ë¥˜ ì¶”ì  ë¶„ì„
   - ì¶”ì  ì¸ì‚¬ì´íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²¬ê³ í•œ ì˜¤ë¥˜ ì²˜ë¦¬ êµ¬í˜„

4. **í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ ì„¤ì •**
   - í”„ë¡œë•ì…˜ ì¤€ë¹„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ìƒì„±
   - ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„° ë° íƒœê·¸ ì „ëµ êµ¬í˜„
   - ì„±ëŠ¥ ì•Œë¦¼ ì„ê³„ê°’ ì„¤ì •
   - LangSmith ë°ì´í„°ì—ì„œ ìë™ ë¦¬í¬íŒ… êµ¬ì¶•

### ğŸ’¡ ì°½ì˜ ê³¼ì œ
5. **ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•**
   - LangSmith APIë¥¼ ì‚¬ìš©í•œ ì»¤ìŠ¤í…€ ëŒ€ì‹œë³´ë“œ ìƒì„±
   - ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ ì‹œê°í™”
   - ì•Œë¦¼ ë° ê²½ê³  ì‹œìŠ¤í…œ êµ¬í˜„

## ğŸ”— ê´€ë ¨ ìë£Œ
- **ì´ì „ í•™ìŠµ**: [6.4 Vector Stores](./6.4_Vector_Stores.md)
- **ë‹¤ìŒ í•™ìŠµ**: [6.6 RetrievalQA](./6.6_RetrievalQA.md)
- **LangSmith ë¬¸ì„œ**: [ê³µì‹ LangSmith ë¬¸ì„œ](https://docs.smith.langchain.com/)
- **ì„¤ì • ê°€ì´ë“œ**: [LangSmith ë¹ ë¥¸ ì‹œì‘](https://docs.smith.langchain.com/getting-started)

---

ğŸ’¡ **í•µì‹¬ ì •ë¦¬**: LangSmithëŠ” RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì— í•„ìˆ˜ì ì¸ ê´€ì°°ì„±ì„ ì œê³µí•˜ì—¬, ê°œë°œìê°€ ì „ë¡€ ì—†ëŠ” ê°€ì‹œì„±ìœ¼ë¡œ ì²´ì¸ì„ ì´í•´í•˜ê³ , ë””ë²„ê¹…í•˜ê³ , ìµœì í™”í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ë³µì¡í•œ ì²´ì¸ ë””ë²„ê¹…ì„ ë¸”ë™ë°•ìŠ¤ì—ì„œ íˆ¬ëª…í•˜ê³  ë¶„ì„ ê°€ëŠ¥í•œ í”„ë¡œì„¸ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.