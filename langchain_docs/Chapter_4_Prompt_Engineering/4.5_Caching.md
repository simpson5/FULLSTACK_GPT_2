# ğŸ“– Section 4.5: Caching - LLM ì‘ë‹µ ìºì‹±

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- âœ… LLM ìºì‹±ì˜ í•„ìš”ì„±ê³¼ ë¹„ìš© ì ˆê° íš¨ê³¼ ì´í•´
- âœ… ë‹¤ì–‘í•œ ìºì‹œ ë°±ì—”ë“œ (ë©”ëª¨ë¦¬, SQLite, Redis) í™œìš©
- âœ… ìºì‹œ ì ì¤‘ë¥  ìµœì í™” ì „ëµ ìˆ˜ë¦½
- âœ… í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œì˜ ìºì‹± ëª¨ë²” ì‚¬ë¡€ ì ìš©

## ğŸ§  í•µì‹¬ ê°œë…

### LLM ìºì‹±ì´ë€?
**LLM ìºì‹±**ì€ ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•œ LLM ì‘ë‹µì„ ì €ì¥í•˜ì—¬, ê°™ì€ ì§ˆë¬¸ì´ ë°˜ë³µë  ë•Œ API í˜¸ì¶œ ì—†ì´ ì €ì¥ëœ ë‹µë³€ì„ ì¦‰ì‹œ ë°˜í™˜í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.

```mermaid
graph TD
    A[ì‚¬ìš©ì ì§ˆë¬¸] --> B{ìºì‹œì— ë‹µë³€ ìˆìŒ?}
    B -->|Yes| C[ìºì‹œì—ì„œ ì¦‰ì‹œ ë°˜í™˜]
    B -->|No| D[LLM API í˜¸ì¶œ]
    D --> E[ìƒˆë¡œìš´ ë‹µë³€ ìƒì„±]
    E --> F[ìºì‹œì— ì €ì¥]
    F --> G[ì‚¬ìš©ìì—ê²Œ ë°˜í™˜]
    
    C --> H[ğŸ’° ë¹„ìš© ì ˆì•½]
    G --> H
    C --> I[âš¡ ë¹ ë¥¸ ì‘ë‹µ]
    G --> I
```

### ìºì‹±ì˜ ì¥ì 

| ì¥ì  | ì„¤ëª… | ì‹¤ì œ íš¨ê³¼ |
|------|------|-----------|
| **ë¹„ìš© ì ˆì•½** | ì¤‘ë³µ API í˜¸ì¶œ ì œê±° | 50-90% ë¹„ìš© ì ˆê° |
| **ì‘ë‹µ ì†ë„** | ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì œê±° | 0.1ì´ˆ vs 3-10ì´ˆ |
| **ì•ˆì •ì„±** | API ì¥ì•  ì‹œ ëŒ€ì•ˆ ì œê³µ | ì„œë¹„ìŠ¤ ì—°ì†ì„± í™•ë³´ |
| **ì‚¬ìš©ì ê²½í—˜** | ì¦‰ì‹œ ì‘ë‹µìœ¼ë¡œ ë§Œì¡±ë„ í–¥ìƒ | ì´íƒˆë¥  ê°ì†Œ |

## ğŸ“‹ ì£¼ìš” í´ë˜ìŠ¤/í•¨ìˆ˜ ë ˆí¼ëŸ°ìŠ¤

### ì „ì—­ ìºì‹œ ì„¤ì •
```python
from langchain.globals import set_llm_cache, set_debug
from langchain.cache import InMemoryCache, SQLiteCache

def set_llm_cache(cache_instance):
    """
    ğŸ“‹ ê¸°ëŠ¥: ì „ì—­ LLM ìºì‹œ ì„¤ì •
    ğŸ“¥ ì…ë ¥: ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ (InMemoryCache, SQLiteCache ë“±)
    ğŸ“¤ ì¶œë ¥: ì—†ìŒ
    ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í•œ ë²ˆ ì„¤ì •
    """
```

### InMemoryCache
```python
class InMemoryCache:
    def __init__(self):
        """
        ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹œ - ê°œë°œ ë° í…ŒìŠ¤íŠ¸ìš©
        
        íŠ¹ì§•:
        - ê°€ì¥ ë¹ ë¥¸ ì ‘ê·¼ ì†ë„
        - í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ë°ì´í„° ì†ì‹¤
        - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
        """
```

### SQLiteCache
```python
class SQLiteCache:
    def __init__(self, database_path: str = "langchain.db"):
        """
        SQLite ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ìºì‹œ - ì˜êµ¬ ì €ì¥ìš©
        
        Args:
            database_path: SQLite íŒŒì¼ ê²½ë¡œ
            
        íŠ¹ì§•:
        - ì˜êµ¬ ì €ì¥ (ì¬ì‹œì‘ í›„ì—ë„ ìœ ì§€)
        - íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ê³µìœ  ê°€ëŠ¥
        - ì¤‘ê°„ ì •ë„ì˜ ì„±ëŠ¥
        """
```

**ğŸ“Œ ì§€ì›ë˜ëŠ” ìºì‹œ ë°±ì—”ë“œ**:
- `InMemoryCache`: ë©”ëª¨ë¦¬ ìºì‹œ (ë¹ ë¦„, ì„ì‹œ)
- `SQLiteCache`: SQLite ë°ì´í„°ë² ì´ìŠ¤ (ì˜êµ¬, ë‹¨ì¼ ì„œë²„)
- `RedisCache`: Redis ì„œë²„ (ì˜êµ¬, ë¶„ì‚° ê°€ëŠ¥)
- `FullLLMCache`: ì™„ì „í•œ ìš”ì²­-ì‘ë‹µ ìºì‹±

## ğŸ”§ ë™ì‘ ê³¼ì • ìƒì„¸

### ê¸°ë³¸ ìºì‹± ì„¤ì • ë° ì‚¬ìš©
```python
# Step 1: í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain.chat_models import ChatOpenAI
from langchain.globals import set_llm_cache, set_debug
from langchain.cache import InMemoryCache, SQLiteCache
import time

# Step 2: ìºì‹œ ì„¤ì • (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
set_llm_cache(InMemoryCache())  # ğŸ“Œ ìš©ë„: ë©”ëª¨ë¦¬ ìºì‹œ í™œì„±í™”, íƒ€ì…: InMemoryCache

# ì„ íƒì‚¬í•­: ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” (ìºì‹œ ë™ì‘ í™•ì¸ìš©)
# set_debug(True)  # ğŸ“Œ ìš©ë„: ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ë¡œê·¸ ì¶œë ¥

# Step 3: ëª¨ë¸ ì´ˆê¸°í™” (ìºì‹œ ì„¤ì • í›„ì— ìˆ˜í–‰)
chat = ChatOpenAI(
    temperature=0.1,  # ğŸ“Œ ìš©ë„: ì¼ê´€ëœ ì‘ë‹µìœ¼ë¡œ ìºì‹œ íš¨ìœ¨ì„± ì¦ëŒ€
    # streaming=True,  # ğŸ“Œ ì£¼ì˜: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œëŠ” ìºì‹±ê³¼ ì¶©ëŒí•  ìˆ˜ ìˆìŒ
)

# Step 4: ì²« ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ ë¯¸ìŠ¤ - API í˜¸ì¶œ ë°œìƒ)
question = "How do you make italian pasta?"  # ğŸ“Œ ìš©ë„: í…ŒìŠ¤íŠ¸ ì§ˆë¬¸, íƒ€ì…: str

print("=== ì²« ë²ˆì§¸ í˜¸ì¶œ (API í˜¸ì¶œ) ===")
start_time = time.time()  # ğŸ“Œ ìš©ë„: ì‘ë‹µ ì‹œê°„ ì¸¡ì • ì‹œì‘
response1 = chat.predict(question)
end_time = time.time()
print(f"ì‘ë‹µ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
print(f"ì‘ë‹µ ê¸¸ì´: {len(response1)}ì")

# Step 5: ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ íˆíŠ¸ - ì¦‰ì‹œ ë°˜í™˜)
print("\n=== ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œì—ì„œ ë°˜í™˜) ===")
start_time = time.time()
response2 = chat.predict(question)  # ğŸ“Œ ë™ì¼í•œ ì§ˆë¬¸
end_time = time.time()
print(f"ì‘ë‹µ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
print(f"ì‘ë‹µ ë™ì¼ì„±: {response1 == response2}")
```

## ğŸ’» ì‹¤ì „ ì˜ˆì œ

### 1. ë©”ëª¨ë¦¬ ìºì‹œ vs SQLite ìºì‹œ ë¹„êµ
```python
from langchain.chat_models import ChatOpenAI
from langchain.globals import set_llm_cache
from langchain.cache import InMemoryCache, SQLiteCache
import time
import os

# ğŸ¯ ì‹¤ìŠµ ëª©í‘œ: ë‹¤ì–‘í•œ ìºì‹œ ë°±ì—”ë“œ ì„±ëŠ¥ ë¹„êµ

def test_cache_performance(cache_type, cache_instance, test_questions):
    """
    ğŸ“‹ ê¸°ëŠ¥: ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    ğŸ“¥ ì…ë ¥: ìºì‹œ íƒ€ì…, ì¸ìŠ¤í„´ìŠ¤, í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    ğŸ“¤ ì¶œë ¥: ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼
    ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ìµœì  ìºì‹œ ë°±ì—”ë“œ ì„ íƒ
    """
    print(f"\n=== {cache_type} ìºì‹œ í…ŒìŠ¤íŠ¸ ===")
    
    # ìºì‹œ ì„¤ì •
    set_llm_cache(cache_instance)
    chat = ChatOpenAI(temperature=0.1)
    
    results = {
        "first_call_times": [],   # ğŸ“Œ ìš©ë„: ì²« í˜¸ì¶œ ì‹œê°„ ì €ì¥
        "cached_call_times": [],  # ğŸ“Œ ìš©ë„: ìºì‹œ íˆíŠ¸ ì‹œê°„ ì €ì¥
        "cache_hit_ratio": 0      # ğŸ“Œ ìš©ë„: ìºì‹œ ì ì¤‘ë¥ 
    }
    
    for i, question in enumerate(test_questions):
        # ì²« ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ ë¯¸ìŠ¤)
        start_time = time.time()
        response1 = chat.predict(question)
        first_call_time = time.time() - start_time
        results["first_call_times"].append(first_call_time)
        
        # ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ íˆíŠ¸)
        start_time = time.time()
        response2 = chat.predict(question)
        cached_call_time = time.time() - start_time
        results["cached_call_times"].append(cached_call_time)
        
        print(f"ì§ˆë¬¸ {i+1}: ì²« í˜¸ì¶œ {first_call_time:.2f}s, ìºì‹œ {cached_call_time:.2f}s")
        print(f"ì†ë„ í–¥ìƒ: {first_call_time/cached_call_time:.1f}ë°°")
    
    return results

# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
test_questions = [
    "What is the capital of France?",
    "How do you make chocolate cake?",
    "Explain quantum computing in simple terms.",
    "What are the benefits of renewable energy?"
]

# 1. ë©”ëª¨ë¦¬ ìºì‹œ í…ŒìŠ¤íŠ¸
memory_results = test_cache_performance(
    "InMemory", 
    InMemoryCache(), 
    test_questions
)

# 2. SQLite ìºì‹œ í…ŒìŠ¤íŠ¸
sqlite_results = test_cache_performance(
    "SQLite", 
    SQLiteCache("test_cache.db"), 
    test_questions
)

# ê²°ê³¼ ë¹„êµ
print("\n=== ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ===")
print(f"ë©”ëª¨ë¦¬ ìºì‹œ í‰ê·  íˆíŠ¸ ì‹œê°„: {sum(memory_results['cached_call_times'])/len(memory_results['cached_call_times']):.4f}ì´ˆ")
print(f"SQLite ìºì‹œ í‰ê·  íˆíŠ¸ ì‹œê°„: {sum(sqlite_results['cached_call_times'])/len(sqlite_results['cached_call_times']):.4f}ì´ˆ")

# í…ŒìŠ¤íŠ¸ í›„ ì •ë¦¬
if os.path.exists("test_cache.db"):
    os.remove("test_cache.db")
```

### 2. í”„ë¡œë•ì…˜ìš© SQLite ìºì‹œ ì„¤ì •
```python
from langchain.chat_models import ChatOpenAI
from langchain.globals import set_llm_cache
from langchain.cache import SQLiteCache
import os
from datetime import datetime

# ğŸ¯ ì‹¤ìŠµ ëª©í‘œ: í”„ë¡œë•ì…˜ í™˜ê²½ìš© ìºì‹œ ì‹œìŠ¤í…œ êµ¬ì¶•

class ProductionCacheManager:
    """í”„ë¡œë•ì…˜ í™˜ê²½ìš© ìºì‹œ ê´€ë¦¬ì"""
    
    def __init__(self, cache_dir: str = "./cache", db_name: str = None):
        """
        ğŸ“‹ ê¸°ëŠ¥: í”„ë¡œë•ì…˜ìš© ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        ğŸ“¥ ì…ë ¥: ìºì‹œ ë””ë ‰í† ë¦¬, ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
        ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œ ìºì‹œ í™˜ê²½ êµ¬ì„±
        """
        self.cache_dir = cache_dir  # ğŸ“Œ ìš©ë„: ìºì‹œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(cache_dir, exist_ok=True)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ ì„¤ì • (ë‚ ì§œë³„ ë˜ëŠ” ê¸°ë³¸)
        if db_name is None:
            today = datetime.now().strftime("%Y%m%d")
            db_name = f"llm_cache_{today}.db"
        
        self.db_path = os.path.join(cache_dir, db_name)  # ğŸ“Œ ìš©ë„: DB íŒŒì¼ ê²½ë¡œ
        
        # ìºì‹œ ì„¤ì •
        self.setup_cache()
    
    def setup_cache(self):
        """ìºì‹œ ì‹œìŠ¤í…œ ì„¤ì •"""
        cache_instance = SQLiteCache(self.db_path)
        set_llm_cache(cache_instance)
        print(f"âœ… SQLite ìºì‹œ ì„¤ì • ì™„ë£Œ: {self.db_path}")
    
    def get_cache_stats(self):
        """
        ğŸ“‹ ê¸°ëŠ¥: ìºì‹œ í†µê³„ ì •ë³´ ë°˜í™˜
        ğŸ“¤ ì¶œë ¥: ìºì‹œ íŒŒì¼ í¬ê¸°, ìƒì„± ì‹œê°„ ë“±
        ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ìºì‹œ ìƒíƒœ ëª¨ë‹ˆí„°ë§
        """
        if os.path.exists(self.db_path):
            size = os.path.getsize(self.db_path)
            created = datetime.fromtimestamp(os.path.getctime(self.db_path))
            return {
                "file_size": f"{size / 1024:.2f} KB",
                "created_at": created.strftime("%Y-%m-%d %H:%M:%S"),
                "file_path": self.db_path
            }
        return None
    
    def cleanup_old_caches(self, days_to_keep: int = 7):
        """
        ğŸ“‹ ê¸°ëŠ¥: ì˜¤ë˜ëœ ìºì‹œ íŒŒì¼ ì •ë¦¬
        ğŸ“¥ ì…ë ¥: ë³´ê´€í•  ì¼ìˆ˜
        ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ë””ìŠ¤í¬ ê³µê°„ ê´€ë¦¬
        """
        import glob
        from datetime import timedelta
        
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        cache_files = glob.glob(os.path.join(self.cache_dir, "llm_cache_*.db"))
        
        removed_count = 0
        for file_path in cache_files:
            if datetime.fromtimestamp(os.path.getctime(file_path)) < cutoff_date:
                os.remove(file_path)
                removed_count += 1
                print(f"ğŸ—‘ï¸  ì œê±°ëœ ìºì‹œ íŒŒì¼: {file_path}")
        
        print(f"ğŸ“Š ì´ {removed_count}ê°œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

# ì‚¬ìš© ì˜ˆì‹œ
def main():
    # í”„ë¡œë•ì…˜ ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    cache_manager = ProductionCacheManager()
    
    # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    chat = ChatOpenAI(temperature=0.1)
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    questions = [
        "What are the latest trends in AI?",
        "How to optimize database performance?",
        "Best practices for API design?"
    ]
    
    print("=== ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    for i, question in enumerate(questions, 1):
        print(f"\nì§ˆë¬¸ {i}: {question}")
        
        # ì²« ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ ë¯¸ìŠ¤)
        start_time = time.time()
        response = chat.predict(question)
        first_time = time.time() - start_time
        
        # ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ íˆíŠ¸)
        start_time = time.time()
        cached_response = chat.predict(question)
        cached_time = time.time() - start_time
        
        print(f"ì²« í˜¸ì¶œ: {first_time:.2f}ì´ˆ")
        print(f"ìºì‹œ í˜¸ì¶œ: {cached_time:.4f}ì´ˆ")
        print(f"ì†ë„ í–¥ìƒ: {first_time/cached_time:.1f}ë°°")
        print(f"ì‘ë‹µ ì¼ì¹˜: {'âœ…' if response == cached_response else 'âŒ'}")
    
    # ìºì‹œ í†µê³„ ì¶œë ¥
    stats = cache_manager.get_cache_stats()
    if stats:
        print(f"\n=== ìºì‹œ í†µê³„ ===")
        for key, value in stats.items():
            print(f"{key}: {value}")
    
    # ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬ (ì˜ˆì‹œ)
    cache_manager.cleanup_old_caches(days_to_keep=7)

if __name__ == "__main__":
    main()
```

### 3. ìºì‹œ ë¬´íš¨í™” ë° ê´€ë¦¬
```python
from langchain.globals import set_llm_cache
from langchain.cache import SQLiteCache
import sqlite3
import json

class AdvancedCacheManager:
    """ê³ ê¸‰ ìºì‹œ ê´€ë¦¬ ê¸°ëŠ¥"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        set_llm_cache(SQLiteCache(db_path))
    
    def clear_cache(self):
        """
        ğŸ“‹ ê¸°ëŠ¥: ì „ì²´ ìºì‹œ ì‚­ì œ
        ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ìºì‹œ ë¦¬ì…‹ì´ í•„ìš”í•  ë•Œ
        """
        conn = sqlite3.connect(self.db_path)
        conn.execute("DELETE FROM full_llm_cache")
        conn.commit()
        conn.close()
        print("ğŸ§¹ ìºì‹œê°€ ì™„ì „íˆ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def get_cache_entries(self, limit: int = 10):
        """
        ğŸ“‹ ê¸°ëŠ¥: ìºì‹œ ì—”íŠ¸ë¦¬ ì¡°íšŒ
        ğŸ“¥ ì…ë ¥: ì¡°íšŒí•  ìµœëŒ€ ê°œìˆ˜
        ğŸ“¤ ì¶œë ¥: ìºì‹œ ì—”íŠ¸ë¦¬ ë¦¬ìŠ¤íŠ¸
        ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ìºì‹œ ë‚´ìš© ë¶„ì„
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.execute(
            "SELECT prompt, llm, response, created_at FROM full_llm_cache LIMIT ?", 
            (limit,)
        )
        entries = cursor.fetchall()
        conn.close()
        
        return [
            {
                "prompt": entry[0][:100] + "..." if len(entry[0]) > 100 else entry[0],
                "llm": entry[1],
                "response_length": len(entry[2]),
                "created_at": entry[3] if entry[3] else "Unknown"
            }
            for entry in entries
        ]
    
    def remove_entries_by_pattern(self, pattern: str):
        """
        ğŸ“‹ ê¸°ëŠ¥: íŒ¨í„´ì— ë§ëŠ” ìºì‹œ ì—”íŠ¸ë¦¬ ì‚­ì œ
        ğŸ“¥ ì…ë ¥: ê²€ìƒ‰ íŒ¨í„´ (SQL LIKE íŒ¨í„´)
        ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: íŠ¹ì • ì£¼ì œì˜ ìºì‹œë§Œ ì‚­ì œ
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.execute(
            "DELETE FROM full_llm_cache WHERE prompt LIKE ?", 
            (f"%{pattern}%",)
        )
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        print(f"ğŸ—‘ï¸  '{pattern}' íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ” {deleted_count}ê°œ ì—”íŠ¸ë¦¬ ì‚­ì œ")
        return deleted_count

# ì‚¬ìš© ì˜ˆì‹œ
cache_manager = AdvancedCacheManager("advanced_cache.db")

# ìºì‹œ ì—”íŠ¸ë¦¬ ì¡°íšŒ
entries = cache_manager.get_cache_entries(5)
print("=== ìµœê·¼ ìºì‹œ ì—”íŠ¸ë¦¬ ===")
for i, entry in enumerate(entries, 1):
    print(f"{i}. {entry['prompt']}")
    print(f"   ì‘ë‹µ ê¸¸ì´: {entry['response_length']}ì")

# íŠ¹ì • íŒ¨í„´ ì‚­ì œ
cache_manager.remove_entries_by_pattern("python")
```

## ğŸ” ë³€ìˆ˜/í•¨ìˆ˜ ìƒì„¸ ì„¤ëª…

### í•µì‹¬ ë³€ìˆ˜ë“¤
```python
# ìºì‹œ ì„¤ì • ë³€ìˆ˜
cache_enabled = True        # ğŸ“Œ ìš©ë„: ìºì‹œ í™œì„±í™” í”Œë˜ê·¸, íƒ€ì…: bool
cache_db_path = "cache.db"  # ğŸ“Œ ìš©ë„: SQLite íŒŒì¼ ê²½ë¡œ, íƒ€ì…: str
cache_ttl = 3600           # ğŸ“Œ ìš©ë„: ìºì‹œ ìœ íš¨ ì‹œê°„(ì´ˆ), íƒ€ì…: int

# ì„±ëŠ¥ ì¸¡ì • ë³€ìˆ˜
response_time = 0.0        # ğŸ“Œ ìš©ë„: ì‘ë‹µ ì‹œê°„ ì €ì¥, íƒ€ì…: float
cache_hit_count = 0        # ğŸ“Œ ìš©ë„: ìºì‹œ íˆíŠ¸ íšŸìˆ˜, íƒ€ì…: int
total_requests = 0         # ğŸ“Œ ìš©ë„: ì´ ìš”ì²­ ìˆ˜, íƒ€ì…: int
```

### í•µì‹¬ í•¨ìˆ˜ë“¤
```python
def set_llm_cache(cache_instance) -> None:
    """
    ğŸ“‹ ê¸°ëŠ¥: ì „ì—­ LLM ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •
    ğŸ“¥ ì…ë ¥: ìºì‹œ ë°±ì—”ë“œ ì¸ìŠ¤í„´ìŠ¤
    ğŸ“¤ ì¶œë ¥: ì—†ìŒ
    ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ì‹œì 
    """

def set_debug(enabled: bool) -> None:
    """
    ğŸ“‹ ê¸°ëŠ¥: ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”/ë¹„í™œì„±í™”
    ğŸ“¥ ì…ë ¥: ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
    ğŸ“¤ ì¶œë ¥: ì—†ìŒ
    ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ìºì‹œ ë™ì‘ ë¶„ì„ í•„ìš” ì‹œ
    """

def predict(prompt: str) -> str:
    """
    ğŸ“‹ ê¸°ëŠ¥: LLM ì˜ˆì¸¡ ì‹¤í–‰ (ìºì‹œ ì ìš©)
    ğŸ“¥ ì…ë ¥: í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    ğŸ“¤ ì¶œë ¥: LLM ì‘ë‹µ ë¬¸ìì—´
    ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤: ì¼ë°˜ì ì¸ LLM í˜¸ì¶œ
    """
```

## ğŸ§ª ì‹¤ìŠµ ê³¼ì œ

### ğŸ”¨ ê¸°ë³¸ ê³¼ì œ
1. **ìºì‹œ ì„±ëŠ¥ ì¸¡ì •**: 10ê°œ ì§ˆë¬¸ìœ¼ë¡œ ìºì‹œ ì „í›„ ì„±ëŠ¥ ë¹„êµ
2. **ë‹¤ì–‘í•œ ë°±ì—”ë“œ í…ŒìŠ¤íŠ¸**: InMemory, SQLite ìºì‹œ ì„±ëŠ¥ ë¹„êµ

### ğŸš€ ì‹¬í™” ê³¼ì œ
3. **Redis ìºì‹œ êµ¬í˜„**: Redis ì„œë²„ë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° ìºì‹œ ì‹œìŠ¤í…œ
4. **TTL ìºì‹œ**: ì‹œê°„ ì œí•œì´ ìˆëŠ” ìºì‹œ ì‹œìŠ¤í…œ êµ¬í˜„
```python
# TODO: TTL ê¸°ëŠ¥ì´ ìˆëŠ” ì»¤ìŠ¤í…€ ìºì‹œ êµ¬í˜„
class TTLCache:
    def __init__(self, ttl_seconds: int = 3600):
        self.ttl = ttl_seconds
        # TTL ë¡œì§ êµ¬í˜„
```

5. **ìºì‹œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ**: ìºì‹œ íˆíŠ¸ìœ¨, ì €ì¥ ìš©ëŸ‰ ë“± ëª¨ë‹ˆí„°ë§

### ğŸ’¡ ì°½ì˜ ê³¼ì œ
6. **ìŠ¤ë§ˆíŠ¸ ìºì‹œ**: ì‚¬ìš© ë¹ˆë„ì— ë”°ë¥¸ ìë™ ìºì‹œ ì •ë¦¬
7. **ë¶„ì‚° ìºì‹œ**: ì—¬ëŸ¬ ì„œë²„ ê°„ ìºì‹œ ë™ê¸°í™” ì‹œìŠ¤í…œ

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ìºì‹œ ì „ëµ ì„ íƒ
```python
# ê°œë°œ í™˜ê²½: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
set_llm_cache(InMemoryCache())

# ë‹¨ì¼ ì„œë²„ í”„ë¡œë•ì…˜: ì˜êµ¬ ì €ì¥
set_llm_cache(SQLiteCache("production_cache.db"))

# ë¶„ì‚° í™˜ê²½: Redis ë“± ì‚¬ìš©
# set_llm_cache(RedisCache(redis_url="redis://localhost:6379"))
```

### ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: InMemoryCacheëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í•„ìš”
- **ë””ìŠ¤í¬ ê³µê°„**: SQLiteCacheëŠ” ì •ê¸°ì ì¸ íŒŒì¼ í¬ê¸° ê´€ë¦¬ í•„ìš”
- **ë™ì‹œì„±**: ë‹¤ì¤‘ í”„ë¡œì„¸ìŠ¤ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ ë½ ê³ ë ¤

### ë³´ì•ˆ ì£¼ì˜ì 
- **ë¯¼ê° ì •ë³´**: API í‚¤ë‚˜ ê°œì¸ì •ë³´ê°€ í¬í•¨ëœ ì‘ë‹µ ìºì‹± ì£¼ì˜
- **íŒŒì¼ ê¶Œí•œ**: ìºì‹œ íŒŒì¼ì˜ ì ì ˆí•œ ê¶Œí•œ ì„¤ì •
- **ë°ì´í„° ë³´ì¡´**: ë²•ì  ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ ë°ì´í„° ë³´ì¡´ ì •ì±… ìˆ˜ë¦½

## ğŸ”— ê´€ë ¨ ìë£Œ
- **ì´ì „ í•™ìŠµ**: [4.4 Serialization and Composition](./4.4_Serialization_Composition.md)
- **ë‹¤ìŒ í•™ìŠµ**: [4.6 Serialization](./4.6_Serialization.md)
- **ê´€ë ¨ ì£¼ì œ**: [3.3 OutputParserì™€ LCEL](../Chapter_3_LCEL/3.3_OutputParser_LCEL.md)
- **ì„±ëŠ¥ ìµœì í™”**: [Performance Best Practices](../Examples/Advanced_Projects.md)

---

ğŸ’¡ **í•µì‹¬ ì •ë¦¬**: LLM ìºì‹±ì€ ë¹„ìš© ì ˆê°ê³¼ ì„±ëŠ¥ í–¥ìƒì˜ í•„ìˆ˜ ê¸°ìˆ ì…ë‹ˆë‹¤. ì ì ˆí•œ ìºì‹œ ë°±ì—”ë“œ ì„ íƒê³¼ ê´€ë¦¬ ì „ëµìœ¼ë¡œ 50-90%ì˜ ë¹„ìš© ì ˆê°ê³¼ 10-100ë°°ì˜ ì†ë„ í–¥ìƒì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ìºì‹œ ì „ëµì€ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ì„¤ê³„**í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.