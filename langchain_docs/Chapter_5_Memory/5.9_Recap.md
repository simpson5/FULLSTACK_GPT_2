# ğŸ“š Section 5.9: Memory Systems Recap - Chapter 5 ì¢…í•© ì •ë¦¬

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- âœ… Chapter 5ì—ì„œ ë‹¤ë£¬ ëª¨ë“  ë©”ëª¨ë¦¬ íƒ€ì…ì˜ íŠ¹ì§•ê³¼ ìš©ë„ ì •ë¦¬
- âœ… ë©”ëª¨ë¦¬ ì„ íƒ ê¸°ì¤€ê³¼ ìµœì í™” ì „ëµ ìˆ˜ë¦½
- âœ… ì‹¤ë¬´ ì ìš©ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„¤ê³„ ê°€ì´ë“œë¼ì¸
- âœ… ì„±ëŠ¥ ë¹„êµì™€ ë¹„ìš© ë¶„ì„ì„ í†µí•œ ì˜ì‚¬ê²°ì • ì§€ì›

## ğŸ§  Memory Systems ì „ì²´ ê°œìš”

### LangChain Memory ìƒíƒœê³„
```mermaid
graph TD
    A[LangChain Memory] --> B[Buffer-Based]
    A --> C[Summary-Based]
    A --> D[Knowledge-Based]
    A --> E[Integration Methods]
    
    B --> F[ConversationBufferMemory<br/>ì „ì²´ ëŒ€í™” ì €ì¥]
    B --> G[ConversationBufferWindowMemory<br/>ìœˆë„ìš° í¬ê¸° ì œí•œ]
    
    C --> H[ConversationSummaryMemory<br/>LLM ìš”ì•½]
    C --> I[ConversationSummaryBufferMemory<br/>í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼]
    
    D --> J[ConversationKGMemory<br/>ì§€ì‹ ê·¸ë˜í”„]
    
    E --> K[LLMChain Integration<br/>ìë™ ë©”ëª¨ë¦¬]
    E --> L[Chat-Based Memory<br/>ë©”ì‹œì§€ ê°ì²´]
    E --> M[LCEL Integration<br/>ìˆ˜ë™ ì œì–´]
    
    style F fill:#FFB6C1,stroke:#FF69B4,stroke-width:2px
    style G fill:#FFB6C1,stroke:#FF69B4,stroke-width:2px
    style H fill:#98FB98,stroke:#228B22,stroke-width:2px
    style I fill:#98FB98,stroke:#228B22,stroke-width:2px
    style J fill:#87CEEB,stroke:#4682B4,stroke-width:2px
    style K fill:#DDA0DD,stroke:#9370DB,stroke-width:2px
    style L fill:#F0E68C,stroke:#DAA520,stroke-width:2px
    style M fill:#F4A460,stroke:#D2691E,stroke-width:2px
```

## ğŸ“Š ë©”ëª¨ë¦¬ íƒ€ì…ë³„ ìƒì„¸ ë¹„êµ

### ì„±ëŠ¥ íŠ¹ì„± ë§¤íŠ¸ë¦­ìŠ¤
```mermaid
graph TB
    subgraph "í† í° íš¨ìœ¨ì„± ìŠ¤í™íŠ¸ëŸ¼"
        A[ë§¤ìš° ë¹„íš¨ìœ¨ì ] --> B[ë¹„íš¨ìœ¨ì ] --> C[ë³´í†µ] --> D[íš¨ìœ¨ì ] --> E[ë§¤ìš° íš¨ìœ¨ì ]
        
        A1[BufferMemory<br/>ê¸´ ëŒ€í™”] --> A
        B1[WindowMemory<br/>ì¤‘ê°„ ëŒ€í™”] --> B
        C1[SummaryBufferMemory<br/>ì ì‘ì ] --> C
        D1[SummaryMemory<br/>ê¸´ ëŒ€í™”] --> D
        E1[KGMemory<br/>êµ¬ì¡°í™”ëœ ì •ë³´] --> E
    end
    
    style A1 fill:#FF6B6B
    style B1 fill:#FFA07A
    style C1 fill:#FFD700
    style D1 fill:#98FB98
    style E1 fill:#87CEEB
```

### ìƒì„¸ ë¹„êµí‘œ

| ë©”ëª¨ë¦¬ íƒ€ì… | í† í° íš¨ìœ¨ì„± | ì •ë³´ ë³´ì¡´ | êµ¬í˜„ ë³µì¡ë„ | ì´ˆê¸° ë¹„ìš© | ì¥ê¸° ë¹„ìš© | ì‚¬ìš© ì‚¬ë¡€ |
|-------------|-------------|-----------|-------------|-----------|-----------|-----------|
| **ConversationBufferMemory** | âŒ ë§¤ìš° ë‚®ìŒ | âœ… ì™„ë²½ | ğŸŸ¢ ë§¤ìš° ê°„ë‹¨ | ğŸŸ¢ ë‚®ìŒ | âŒ ë§¤ìš° ë†’ìŒ | ì§§ì€ ëŒ€í™”, ê°œë°œ/í…ŒìŠ¤íŠ¸ |
| **ConversationBufferWindowMemory** | ğŸŸ¡ ë³´í†µ | ğŸŸ¡ ë¶€ë¶„ì  | ğŸŸ¢ ê°„ë‹¨ | ğŸŸ¢ ë‚®ìŒ | ğŸŸ¡ ë³´í†µ | ì¼ë°˜ì  ëŒ€í™”, ì œí•œëœ ì»¨í…ìŠ¤íŠ¸ |
| **ConversationSummaryMemory** | âœ… ë†’ìŒ | ğŸŸ¡ ìš”ì•½ëœ ì •ë³´ | ğŸŸ¡ ë³´í†µ | âŒ ë†’ìŒ | âœ… ë‚®ìŒ | ê¸´ ëŒ€í™”, ë¹„ìš© íš¨ìœ¨ì„± ì¤‘ìš” |
| **ConversationSummaryBufferMemory** | âœ… ë§¤ìš° ë†’ìŒ | âœ… ìš°ìˆ˜ | ğŸŸ¡ ë³´í†µ | ğŸŸ¡ ë³´í†µ | âœ… ë‚®ìŒ | í”„ë¡œë•ì…˜ í™˜ê²½, ê· í˜• í•„ìš” |
| **ConversationKGMemory** | âœ… ë§¤ìš° ë†’ìŒ | ğŸŸ¡ êµ¬ì¡°í™”ëœ ì •ë³´ | âŒ ë³µì¡ | âŒ ë†’ìŒ | âœ… ë‚®ìŒ | ë³µì¡í•œ ê´€ê³„, ì¥ê¸° ê¸°ì–µ |

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ëŒ€í™” íšŒìˆ˜ë³„ í† í° ì‚¬ìš©ëŸ‰)

```mermaid
xychart-beta
    title "ëŒ€í™” íšŒìˆ˜ë³„ í† í° ì‚¬ìš©ëŸ‰ ë¹„êµ"
    x-axis [5, 10, 20, 50, 100]
    y-axis "í† í° ìˆ˜" 0 --> 5000
    
    line "BufferMemory" [200, 600, 1500, 4000, 8000]
    line "WindowMemory" [200, 400, 600, 600, 600]
    line "SummaryMemory" [300, 400, 500, 700, 900]
    line "SummaryBufferMemory" [300, 450, 550, 650, 750]
    line "KGMemory" [250, 300, 350, 450, 600]
```

## ğŸ› ï¸ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ

### 1. ë©”ëª¨ë¦¬ ì„ íƒ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬

```mermaid
graph TD
    A[ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„ íƒ] --> B{ì˜ˆìƒ ëŒ€í™” ê¸¸ì´}
    
    B -->|ì§§ìŒ<10íšŒ| C[ConversationBufferMemory]
    B -->|ì¤‘ê°„ 10-30íšŒ| D{ë¹„ìš© ë¯¼ê°ë„}
    B -->|ê¸¸ìŒ 30+íšŒ| E{ì •í™•ë„ vs ë¹„ìš©}
    
    D -->|ë¹„ìš© ì¤‘ìš”| F[ConversationBufferWindowMemory]
    D -->|ì •í™•ë„ ì¤‘ìš”| G[ConversationSummaryBufferMemory]
    
    E -->|ë¹„ìš© ìµœìš°ì„ | H[ConversationSummaryMemory]
    E -->|ì •í™•ë„ ìµœìš°ì„ | I[ConversationSummaryBufferMemory]
    E -->|êµ¬ì¡°í™” ì¤‘ìš”| J[ConversationKGMemory]
    
    style C fill:#FFB6C1
    style F fill:#FFA07A
    style G fill:#98FB98
    style H fill:#87CEEB
    style I fill:#98FB98
    style J fill:#DDA0DD
```

### 2. ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¶Œì¥ ë©”ëª¨ë¦¬

#### ğŸ¤– ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡
```python
# ê¶Œì¥: ConversationSummaryBufferMemory
memory = ConversationSummaryBufferMemory(
    llm=ChatOpenAI(temperature=0.1, model="gpt-3.5-turbo"),
    max_token_limit=500,  # ì ë‹¹í•œ ë²„í¼ í¬ê¸°
    return_messages=True
)

# ì´ìœ :
# âœ… ê³ ê° ì •ë³´ ë³´ì¡´ (ìµœê·¼ ëŒ€í™”ëŠ” ì™„ì „ ë³´ì¡´)
# âœ… ì¥ì‹œê°„ ìƒë‹´ ì§€ì› (ìš”ì•½ìœ¼ë¡œ í† í° íš¨ìœ¨ì„±)
# âœ… ê· í˜•ì¡íŒ ë¹„ìš© êµ¬ì¡°
```

#### ğŸ“š êµìœ¡/íŠœí„°ë§ ì‹œìŠ¤í…œ
```python
# ê¶Œì¥: ConversationKGMemory
memory = ConversationKGMemory(
    llm=ChatOpenAI(temperature=0.1),
    k=15,  # ë” ë§ì€ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
    return_messages=True
)

# ì´ìœ :
# âœ… í•™ìŠµ ì§„ë„ì™€ ê°œë… ê´€ê³„ ì¶”ì 
# âœ… í•™ìŠµì íŠ¹ì„±ê³¼ ì„ í˜¸ë„ ê¸°ì–µ
# âœ… êµ¬ì¡°í™”ëœ ì§€ì‹ ê´€ë¦¬
```

#### ğŸ’¼ ì—…ë¬´ ì–´ì‹œìŠ¤í„´íŠ¸
```python
# ê¶Œì¥: Multi-Memory ì‹œìŠ¤í…œ
class WorkAssistantMemory:
    def __init__(self):
        # ì¼ë°˜ ëŒ€í™” ë©”ëª¨ë¦¬
        self.conversation = ConversationSummaryBufferMemory(
            llm=llm, max_token_limit=300, memory_key="conversation"
        )
        
        # ì‘ì—…/í”„ë¡œì íŠ¸ ë©”ëª¨ë¦¬
        self.tasks = ConversationKGMemory(
            llm=llm, k=20, memory_key="tasks"
        )
        
        # ê°œì¸ ì •ë³´ ë©”ëª¨ë¦¬
        self.profile = ConversationBufferWindowMemory(
            k=5, memory_key="profile"
        )

# ì´ìœ :
# âœ… ë‹¤ì–‘í•œ ì»¨í…ìŠ¤íŠ¸ ë¶„ë¦¬ ê´€ë¦¬
# âœ… ì‘ì—… ê´€ê³„ì„± ì¶”ì  (KG)
# âœ… ìµœê·¼ ì„ í˜¸ë„ ìœ ì§€ (Window)
```

### 3. í†µí•© ë°©ì‹ ì„ íƒ ê°€ì´ë“œ

#### LLMChain vs LCEL ë¹„êµ

```python
# ğŸ”§ LLMChain: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
from langchain.chains import LLMChain

chain = LLMChain(
    llm=llm,
    prompt=prompt,
    memory=memory,  # ìë™ ë©”ëª¨ë¦¬ ì—°ê²°
    verbose=True
)

# ì¥ì : ê°„ë‹¨, ë¹ ë¥¸ ì‹œì‘
# ë‹¨ì : ì œí•œëœ ì»¤ìŠ¤í„°ë§ˆì´ì§•

# âš¡ LCEL: í”„ë¡œë•ì…˜ í™˜ê²½
from langchain.schema.runnable import RunnablePassthrough

chain = (
    RunnablePassthrough.assign(
        chat_history=lambda _: memory.load_memory_variables({})["history"]
    )
    | prompt
    | llm
)

# ì¥ì : ì™„ì „í•œ ì œì–´, í™•ì¥ ê°€ëŠ¥
# ë‹¨ì : ë³µì¡, ìˆ˜ë™ ë©”ëª¨ë¦¬ ê´€ë¦¬ í•„ìš”
```

## ğŸ’° ë¹„ìš© ìµœì í™” ì „ëµ

### 1. í† í° ë¹„ìš© ë¶„ì„ ë„êµ¬
```python
import tiktoken
from typing import Dict, Any

class MemoryCostAnalyzer:
    """ë©”ëª¨ë¦¬ ì‚¬ìš© ë¹„ìš© ë¶„ì„ ë„êµ¬"""
    
    def __init__(self):
        self.encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
        
        # ëª¨ë¸ë³„ ë¹„ìš© (2024ë…„ ê¸°ì¤€, USD per 1K tokens)
        self.costs = {
            "gpt-3.5-turbo": {"input": 0.0010, "output": 0.0020},
            "gpt-4": {"input": 0.0300, "output": 0.0600},
            "gpt-4-turbo": {"input": 0.0100, "output": 0.0300}
        }
    
    def analyze_memory_cost(
        self, 
        memory_content: str, 
        conversations_per_day: int,
        model: str = "gpt-3.5-turbo"
    ) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ë¹„ìš© ë¶„ì„"""
        
        tokens = len(self.encoding.encode(memory_content))
        daily_tokens = tokens * conversations_per_day
        monthly_tokens = daily_tokens * 30
        
        model_cost = self.costs.get(model, self.costs["gpt-3.5-turbo"])
        
        # ì…ë ¥ í† í° ë¹„ìš© ê³„ì‚° (ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸)
        daily_cost = (daily_tokens / 1000) * model_cost["input"]
        monthly_cost = daily_cost * 30
        
        return {
            "memory_tokens": tokens,
            "daily_tokens": daily_tokens,
            "monthly_tokens": monthly_tokens,
            "daily_cost_usd": daily_cost,
            "monthly_cost_usd": monthly_cost,
            "cost_per_conversation": daily_cost / conversations_per_day,
            "optimization_suggestions": self._get_optimization_suggestions(
                tokens, conversations_per_day
            )
        }
    
    def _get_optimization_suggestions(
        self, 
        tokens: int, 
        conversations_per_day: int
    ) -> List[str]:
        """ë¹„ìš© ìµœì í™” ì œì•ˆ"""
        
        suggestions = []
        
        if tokens > 1000:
            suggestions.append("ConversationSummaryMemory ì‚¬ìš© ê³ ë ¤")
            
        if conversations_per_day > 100:
            suggestions.append("ConversationSummaryBufferMemoryë¡œ ì „í™˜")
            
        if tokens > 2000 and conversations_per_day > 50:
            suggestions.append("ë” ì‘ì€ ëª¨ë¸(gpt-3.5-turbo) ì‚¬ìš©")
            
        if tokens > 5000:
            suggestions.append("ë©”ëª¨ë¦¬ ì••ì¶• ì „ëµ í•„ìš”")
            
        return suggestions

# ì‚¬ìš© ì˜ˆì œ
analyzer = MemoryCostAnalyzer()

# ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ íƒ€ì…ë³„ ë¹„ìš© ë¶„ì„
memory_scenarios = {
    "BufferMemory_Long": "A" * 2000,     # ê¸´ ë²„í¼ ë©”ëª¨ë¦¬
    "WindowMemory": "B" * 500,           # ìœˆë„ìš° ë©”ëª¨ë¦¬
    "SummaryMemory": "C" * 300           # ìš”ì•½ ë©”ëª¨ë¦¬
}

for scenario, content in memory_scenarios.items():
    analysis = analyzer.analyze_memory_cost(content, 100)  # ì¼ì¼ 100íšŒ ëŒ€í™”
    
    print(f"\nğŸ“Š {scenario} ë¹„ìš© ë¶„ì„:")
    print(f"   ì›” ë¹„ìš©: ${analysis['monthly_cost_usd']:.2f}")
    print(f"   ëŒ€í™”ë‹¹ ë¹„ìš©: ${analysis['cost_per_conversation']:.4f}")
    print(f"   ìµœì í™” ì œì•ˆ: {analysis['optimization_suggestions']}")
```

### 2. ë©”ëª¨ë¦¬ ìµœì í™” ì „ëµ

#### A. ë™ì  ë©”ëª¨ë¦¬ ì „í™˜
```python
class AdaptiveMemoryManager:
    """ëŒ€í™” ê¸¸ì´ì— ë”°ë¥¸ ë™ì  ë©”ëª¨ë¦¬ ì „í™˜"""
    
    def __init__(self):
        self.conversation_count = 0
        self.current_memory_type = "buffer"
        
        # ë‹¨ê³„ë³„ ë©”ëª¨ë¦¬ ì„¤ì •
        self.memory_configs = {
            "buffer": {"max_conversations": 10, "memory_class": ConversationBufferMemory},
            "window": {"max_conversations": 30, "memory_class": ConversationBufferWindowMemory},
            "summary": {"max_conversations": float('inf'), "memory_class": ConversationSummaryBufferMemory}
        }
    
    def should_upgrade_memory(self) -> bool:
        """ë©”ëª¨ë¦¬ ì—…ê·¸ë ˆì´ë“œ í•„ìš” ì—¬ë¶€ í™•ì¸"""
        current_config = self.memory_configs[self.current_memory_type]
        return self.conversation_count > current_config["max_conversations"]
    
    def upgrade_memory(self):
        """ë‹¤ìŒ ë ˆë²¨ ë©”ëª¨ë¦¬ë¡œ ì—…ê·¸ë ˆì´ë“œ"""
        if self.current_memory_type == "buffer":
            self.current_memory_type = "window"
        elif self.current_memory_type == "window":
            self.current_memory_type = "summary"
        
        print(f"ğŸ”„ ë©”ëª¨ë¦¬ ì—…ê·¸ë ˆì´ë“œ: {self.current_memory_type}")
```

#### B. ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ê¸°ë²•
```python
def compress_memory_context(memory_content: str, compression_ratio: float = 0.7) -> str:
    """ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì§€ëŠ¥ì  ì••ì¶•"""
    
    # ì¤‘ìš”ë„ ê¸°ë°˜ ë¬¸ì¥ ì„ ë³„
    sentences = memory_content.split('.')
    important_sentences = []
    
    for sentence in sentences:
        importance_score = calculate_importance(sentence)
        if importance_score > compression_ratio:
            important_sentences.append(sentence)
    
    return '. '.join(important_sentences)

def calculate_importance(sentence: str) -> float:
    """ë¬¸ì¥ ì¤‘ìš”ë„ ê³„ì‚°"""
    important_keywords = ["ì´ë¦„", "ì§ì—…", "ì„ í˜¸", "ì¤‘ìš”", "ê²°ì •", "ì•½ì†", "ë¬¸ì œ"]
    
    score = 0.5  # ê¸°ë³¸ ì ìˆ˜
    for keyword in important_keywords:
        if keyword in sentence:
            score += 0.1
    
    return min(score, 1.0)
```

## ğŸš€ ê³ ê¸‰ ë©”ëª¨ë¦¬ íŒ¨í„´

### 1. ë©”ëª¨ë¦¬ í˜ë”ë ˆì´ì…˜ (Federation)
```python
class FederatedMemorySystem:
    """ë¶„ì‚° ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.memory_stores = {
            "short_term": ConversationBufferWindowMemory(k=5),
            "long_term": ConversationSummaryMemory(llm=ChatOpenAI()),
            "knowledge": ConversationKGMemory(llm=ChatOpenAI()),
            "preferences": ConversationBufferMemory()
        }
        
        self.routing_rules = {
            "personal_info": ["knowledge", "preferences"],
            "recent_context": ["short_term", "long_term"],
            "task_related": ["knowledge", "long_term"]
        }
    
    def route_memory(self, content: str, content_type: str):
        """ì»¨í…ì¸  íƒ€ì…ì— ë”°ë¥¸ ë©”ëª¨ë¦¬ ë¼ìš°íŒ…"""
        
        target_stores = self.routing_rules.get(content_type, ["long_term"])
        
        for store_name in target_stores:
            if store_name in self.memory_stores:
                self.memory_stores[store_name].save_context(
                    {"input": content}, 
                    {"output": "ì €ì¥ë¨"}
                )
    
    def retrieve_memory(self, query_type: str) -> str:
        """ì¿¼ë¦¬ íƒ€ì…ì— ë”°ë¥¸ ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        
        relevant_stores = self.routing_rules.get(query_type, ["long_term"])
        combined_context = []
        
        for store_name in relevant_stores:
            if store_name in self.memory_stores:
                store_context = self.memory_stores[store_name].load_memory_variables({})
                combined_context.append(store_context)
        
        return self._merge_contexts(combined_context)
    
    def _merge_contexts(self, contexts: List[Dict]) -> str:
        """ë‹¤ì¤‘ ì»¨í…ìŠ¤íŠ¸ ë³‘í•©"""
        merged = []
        for context in contexts:
            for value in context.values():
                if isinstance(value, str):
                    merged.append(value)
                elif isinstance(value, list):
                    merged.extend([str(item) for item in value])
        
        return " | ".join(merged)
```

### 2. ë©”ëª¨ë¦¬ ë²„ì „ ê´€ë¦¬
```python
class VersionedMemorySystem:
    """ë©”ëª¨ë¦¬ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.memory_versions = {}
        self.current_version = 0
        self.max_versions = 10
    
    def save_memory_snapshot(self, memory: BaseMemory, label: str = None):
        """ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ì €ì¥"""
        
        self.current_version += 1
        version_key = f"v{self.current_version}"
        
        if label:
            version_key = f"{version_key}_{label}"
        
        # ë©”ëª¨ë¦¬ ìƒíƒœ ì§ë ¬í™”
        memory_state = memory.load_memory_variables({})
        self.memory_versions[version_key] = {
            "timestamp": datetime.now(),
            "state": memory_state,
            "metadata": {
                "memory_type": type(memory).__name__,
                "version": self.current_version
            }
        }
        
        # ë²„ì „ ìˆ˜ ì œí•œ
        if len(self.memory_versions) > self.max_versions:
            oldest_version = min(self.memory_versions.keys())
            del self.memory_versions[oldest_version]
    
    def restore_memory_version(self, version_key: str, target_memory: BaseMemory):
        """íŠ¹ì • ë²„ì „ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë³µì›"""
        
        if version_key not in self.memory_versions:
            raise ValueError(f"Version {version_key} not found")
        
        # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        target_memory.clear()
        
        # ì €ì¥ëœ ìƒíƒœ ë³µì›
        saved_state = self.memory_versions[version_key]["state"]
        
        # ì´ëŠ” êµ¬í˜„ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ
        # ì‹¤ì œë¡œëŠ” ë©”ëª¨ë¦¬ íƒ€ì…ë³„ ë³µì› ë¡œì§ í•„ìš”
        print(f"Memory restored to version {version_key}")
    
    def list_versions(self) -> List[Dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ë²„ì „ ëª©ë¡"""
        
        return [
            {
                "version": key,
                "timestamp": info["timestamp"],
                "memory_type": info["metadata"]["memory_type"]
            }
            for key, info in self.memory_versions.items()
        ]
```

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### 1. ë©”ëª¨ë¦¬ í‚¤ ë¶ˆì¼ì¹˜
```python
# âŒ ë¬¸ì œ ìƒí™©
memory = ConversationBufferMemory(memory_key="chat_history")
prompt = ChatPromptTemplate.from_messages([
    MessagesPlaceholder(variable_name="history")  # ë¶ˆì¼ì¹˜!
])

# âœ… í•´ê²° ë°©ë²•
memory = ConversationBufferMemory(memory_key="history")
prompt = ChatPromptTemplate.from_messages([
    MessagesPlaceholder(variable_name="history")  # ì¼ì¹˜
])
```

#### 2. return_messages ì„¤ì • ì˜¤ë¥˜
```python
# âŒ ë¬¸ì œ ìƒí™©
memory = ConversationBufferMemory(return_messages=False)  # ë¬¸ìì—´ ë°˜í™˜
prompt = ChatPromptTemplate.from_messages([...])  # ë©”ì‹œì§€ ê¸°ëŒ€

# âœ… í•´ê²° ë°©ë²•
memory = ConversationBufferMemory(return_messages=True)   # ë©”ì‹œì§€ ë°˜í™˜
prompt = ChatPromptTemplate.from_messages([...])
```

#### 3. í† í° í•œê³„ ì´ˆê³¼
```python
# âŒ ë¬¸ì œ ìƒí™©: ë²„í¼ ë©”ëª¨ë¦¬ê°€ ë„ˆë¬´ í¼
memory = ConversationBufferMemory()  # ì œí•œ ì—†ìŒ

# âœ… í•´ê²° ë°©ë²•: ì ì ˆí•œ ë©”ëª¨ë¦¬ íƒ€ì… ì„ íƒ
if expected_conversation_length > 20:
    memory = ConversationSummaryBufferMemory(
        llm=llm,
        max_token_limit=1000
    )
else:
    memory = ConversationBufferWindowMemory(k=10)
```

### ë””ë²„ê¹… ë„êµ¬
```python
class MemoryDebugger:
    """ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë””ë²„ê¹… ë„êµ¬"""
    
    def diagnose_memory_issues(self, memory: BaseMemory, prompt: Any) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ê´€ë ¨ ë¬¸ì œ ì§„ë‹¨"""
        
        issues = []
        
        # 1. ë©”ëª¨ë¦¬ í‚¤ í™•ì¸
        memory_key = getattr(memory, 'memory_key', 'history')
        
        if hasattr(prompt, 'input_variables'):
            prompt_vars = prompt.input_variables
            if memory_key not in prompt_vars:
                issues.append(f"Memory key '{memory_key}' not in prompt variables {prompt_vars}")
        
        # 2. return_messages ì„¤ì • í™•ì¸
        return_messages = getattr(memory, 'return_messages', False)
        prompt_type = type(prompt).__name__
        
        if prompt_type == "ChatPromptTemplate" and not return_messages:
            issues.append("ChatPromptTemplate requires return_messages=True")
        
        if prompt_type == "PromptTemplate" and return_messages:
            issues.append("PromptTemplate requires return_messages=False")
        
        # 3. ë©”ëª¨ë¦¬ í¬ê¸° í™•ì¸
        memory_vars = memory.load_memory_variables({})
        memory_content = memory_vars.get(memory_key, "")
        
        if isinstance(memory_content, str):
            token_count = len(memory_content.split())
            if token_count > 2000:
                issues.append(f"Memory too large: {token_count} words (consider summary)")
        elif isinstance(memory_content, list):
            if len(memory_content) > 50:
                issues.append(f"Too many messages: {len(memory_content)} (consider window or summary)")
        
        return {
            "issues": issues,
            "memory_type": type(memory).__name__,
            "memory_key": memory_key,
            "return_messages": return_messages,
            "prompt_type": prompt_type,
            "recommendations": self._get_recommendations(issues)
        }
    
    def _get_recommendations(self, issues: List[str]) -> List[str]:
        """ë¬¸ì œ í•´ê²° ê¶Œì¥ì‚¬í•­"""
        
        recommendations = []
        
        for issue in issues:
            if "key" in issue.lower():
                recommendations.append("memory_keyì™€ í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ëª… ì¼ì¹˜ì‹œí‚¤ê¸°")
            elif "return_messages" in issue.lower():
                recommendations.append("ì ì ˆí•œ return_messages ì„¤ì •")
            elif "too large" in issue.lower():
                recommendations.append("SummaryMemory ë˜ëŠ” SummaryBufferMemory ì‚¬ìš©")
            elif "too many" in issue.lower():
                recommendations.append("WindowMemory ë˜ëŠ” ìš”ì•½ ê¸°ë°˜ ë©”ëª¨ë¦¬ ì‚¬ìš©")
        
        return recommendations

# ì‚¬ìš© ì˜ˆì œ
debugger = MemoryDebugger()
diagnosis = debugger.diagnose_memory_issues(memory, prompt)

if diagnosis["issues"]:
    print("ğŸš¨ ë°œê²¬ëœ ë¬¸ì œë“¤:")
    for issue in diagnosis["issues"]:
        print(f"   â€¢ {issue}")
    
    print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    for rec in diagnosis["recommendations"]:
        print(f"   â€¢ {rec}")
```

## ğŸ“ í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… ê¸°ë³¸ ì´í•´ë„ í™•ì¸
- [ ] ê° ë©”ëª¨ë¦¬ íƒ€ì…ì˜ íŠ¹ì§•ê³¼ ì¥ë‹¨ì  ì´í•´
- [ ] ë©”ëª¨ë¦¬ í‚¤ì™€ í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ë§¤ì¹­ ì›ë¦¬ íŒŒì•…
- [ ] return_messages ì„¤ì •ì˜ ì¤‘ìš”ì„± ì´í•´
- [ ] LLMChain vs LCEL ë©”ëª¨ë¦¬ í†µí•© ë°©ì‹ ì°¨ì´ì  íŒŒì•…

### âœ… ì‹¤ë¬´ ì ìš© ëŠ¥ë ¥
- [ ] í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ë©”ëª¨ë¦¬ íƒ€ì… ì„ íƒ ê°€ëŠ¥
- [ ] í† í° ë¹„ìš© ìµœì í™” ì „ëµ ìˆ˜ë¦½ ê°€ëŠ¥
- [ ] ë©”ëª¨ë¦¬ ê´€ë ¨ ì˜¤ë¥˜ ë””ë²„ê¹… ë° í•´ê²° ê°€ëŠ¥
- [ ] ë³µí•©ì ì¸ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„¤ê³„ ê°€ëŠ¥

### âœ… ê³ ê¸‰ í™œìš© ê¸°ìˆ 
- [ ] ë‹¤ì¤‘ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„ ê°€ëŠ¥
- [ ] ë™ì  ë©”ëª¨ë¦¬ ì „í™˜ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
- [ ] ë©”ëª¨ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” ê°€ëŠ¥
- [ ] ì»¤ìŠ¤í…€ ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ ê°œë°œ ê°€ëŠ¥

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„ í•™ìŠµ ë°©í–¥

### 1. ê³ ê¸‰ ë©”ëª¨ë¦¬ íŒ¨í„´
- **ë²¡í„° ê¸°ë°˜ ë©”ëª¨ë¦¬**: ì„ë² ë”©ì„ í™œìš©í•œ ì˜ë¯¸ì  ê²€ìƒ‰
- **í•˜ì´ë¸Œë¦¬ë“œ ë©”ëª¨ë¦¬**: ë‹¤ì¤‘ ì €ì¥ì†Œ í†µí•© ê´€ë¦¬
- **ë¶„ì‚° ë©”ëª¨ë¦¬**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬

### 2. ì„±ëŠ¥ ìµœì í™”
- **ë©”ëª¨ë¦¬ ì••ì¶•**: ì§€ëŠ¥ì  ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ê¸°ë²•
- **ìºì‹± ì „ëµ**: Redis ë“±ì„ í™œìš©í•œ ë©”ëª¨ë¦¬ ìºì‹±
- **ë¹„ë™ê¸° ì²˜ë¦¬**: ëŒ€ê·œëª¨ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì˜ ë¹„ë™ê¸° ê´€ë¦¬

### 3. í”„ë¡œë•ì…˜ ê³ ë ¤ì‚¬í•­
- **ëª¨ë‹ˆí„°ë§**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- **ë³´ì•ˆ**: ë¯¼ê° ì •ë³´ê°€ í¬í•¨ëœ ë©”ëª¨ë¦¬ ë³´ì•ˆ ê´€ë¦¬
- **í™•ì¥ì„±**: ì‚¬ìš©ì ì¦ê°€ì— ë”°ë¥¸ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ í™•ì¥

## ğŸ“š ì¶”ì²œ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain Memory Documentation](https://python.langchain.com/docs/modules/memory/)
- [Memory Types Reference](https://python.langchain.com/docs/modules/memory/types/)
- [LCEL Memory Integration](https://python.langchain.com/docs/expression_language/how_to/memory)

### ì»¤ë®¤ë‹ˆí‹° ë¦¬ì†ŒìŠ¤
- [LangChain GitHub Examples](https://github.com/langchain-ai/langchain/tree/master/docs/docs/modules/memory)
- [Memory Best Practices](https://blog.langchain.dev/memory-best-practices/)
- [Performance Optimization Guide](https://docs.langchain.com/docs/category/performance)

---

## ğŸ’¡ ìµœì¢… ì •ë¦¬

**Chapter 5 Memory Systems**ì—ì„œ ë‹¤ë£¬ ë‚´ìš©ì„ ìš”ì•½í•˜ë©´:

### ğŸ¯ í•µì‹¬ ê°œë…
1. **ë©”ëª¨ë¦¬ íƒ€ì…**: Buffer, Window, Summary, SummaryBuffer, Knowledge Graph
2. **í†µí•© ë°©ì‹**: LLMChain ìë™ í†µí•© vs LCEL ìˆ˜ë™ ì œì–´
3. **ë©”ì‹œì§€ ì²˜ë¦¬**: ë¬¸ìì—´ ê¸°ë°˜ vs ë©”ì‹œì§€ ê°ì²´ ê¸°ë°˜
4. **ë¹„ìš© ìµœì í™”**: í† í° íš¨ìœ¨ì„±ê³¼ ì •ë³´ ë³´ì¡´ì˜ ê· í˜•

### ğŸ› ï¸ ì‹¤ë¬´ ê°€ì´ë“œë¼ì¸
- **ì§§ì€ ëŒ€í™” (< 10íšŒ)**: ConversationBufferMemory
- **ì¼ë°˜ì  ëŒ€í™” (10-30íšŒ)**: ConversationBufferWindowMemory
- **ê¸´ ëŒ€í™” (30+ íšŒ)**: ConversationSummaryBufferMemory
- **ë³µì¡í•œ ê´€ê³„**: ConversationKGMemory
- **í”„ë¡œë•ì…˜ í™˜ê²½**: LCEL ê¸°ë°˜ ì»¤ìŠ¤í…€ êµ¬í˜„

### ğŸš€ ë°œì „ ë°©í–¥
Chapter 5ì˜ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì€ **ëŒ€í™”í˜• AIì˜ í•µì‹¬ ê¸°ë°˜**ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ë³µì¡í•˜ê³  ì§€ëŠ¥ì ì¸ AI ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ë‹¤ìŒ Chapterì—ì„œëŠ”** ì´ëŸ¬í•œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ **ì‹¤ì œ ë¬¸ì„œ ê¸°ë°˜ QA ì‹œìŠ¤í…œ(DocumentGPT)**ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ì™€ ë¬¸ì„œ ê²€ìƒ‰ì´ ê²°í•©ëœ ê³ ê¸‰ AI ì‹œìŠ¤í…œì˜ êµ¬í˜„ì„ í†µí•´ ë”ìš± ì‹¤ë¬´ì ì´ê³  ê°•ë ¥í•œ ê¸°ìˆ ì„ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤.

---

ğŸ‰ **ì¶•í•˜í•©ë‹ˆë‹¤!** Chapter 5 Memory Systems í•™ìŠµì„ ì™„ë£Œí•˜ì…¨ìŠµë‹ˆë‹¤. ì´ì œ LangChainì˜ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ ììœ ìì¬ë¡œ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ëŒ€í™”í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!